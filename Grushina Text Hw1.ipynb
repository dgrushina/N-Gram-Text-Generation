{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Глубинное обучение для текстовых данных, ФКН ВШЭ\n",
    "\n",
    "## Домашнее задание 1: Text Suggestion\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Максимально допустимая оценка за работу — 10 баллов. Сдавать задание после жесткого дедлайна нельзя. При сдачи решения после мягкого дедлайна за каждый день просрочки снимается по одному баллу.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Весь код должен быть написан самостоятельно. Чужим кодом для пользоваться запрещается даже с указанием ссылки на источник. В разумных рамках, конечно. Взять пару очевидных строчек кода для реализации какого-то небольшого функционала можно.\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
    "\n",
    "__Мягкий дедлайн: 02.10.24 23:59__\n",
    "\n",
    "__Жесткий дедлайн: 05.10.24 23:59__\n",
    "\n",
    "\n",
    "### О задании\n",
    "\n",
    "В этом задании вам предстоит реализовать систему, предлагающую удачное продолжение слова или нескольких следующих слов в режиме реального времени по типу тех, которые используются в телефонах, поисковой строке или приложении почты. Полученную систему вам нужно будет обернуть в пользовательский интерфейс с помощью библиотеки [reflex](https://github.com/reflex-dev/reflex), чтобы ей можно было удобно пользоваться, а так же, чтобы убедиться, что все работает как надо. В этот раз вам не придется обучать никаких моделей, мы ограничимся n-граммной генерацией.\n",
    "\n",
    "### Структура\n",
    "\n",
    "Это домашнее задание состоит из двух частей предположительно одинаковых по сложности. В первой вам нужно будет выполнить 5 заданий, по итогам которых вы получите минимально рабочее решение. А во второй, пользуясь тем, что вы уже сделали реализовать полноценную систему подсказки текста с пользовательским интерфейсом. Во второй части мы никак не будем ограничивать вашу фантазию. Делайте что угодно, лишь бы получилось в результате получился удобный фреймворк. Чем лучше у вас будет результат, тем больше баллов вы получите. Если будет совсем хорошо, то мы добавим бонусов сверху по своему усмотрению.\n",
    "\n",
    "### Оценивание\n",
    "При сдаче зададания в anytask вам будет необходимо сдать весь код, а также отчет с подробным описанием техник, которые в применили для создания вашей системы. Не лишним будет также написать и о том, что у вас не получилось и почему.\n",
    "\n",
    "За часть с заданиями можно будет получить до __5__ баллов, за отчет – до __3__ баллов и еще __2__ балла можно будет получить за демонстрацию вашей системы и пользовательского интерфейса. Демонстрацию прикрепляйте в anytask в виде 1-2 минутной записи экрана."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные\n",
    "\n",
    "Для получения текстовых статистик используйте датасет `emails.csv`. Вы можете найти его по [ссылке](https://disk.yandex.ru/d/ikyUhWPlvfXxCg). Он содержит более 500 тысяч электронных писем на английском языке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Union, List, Tuple\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517401"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = pd.read_csv('emails.csv')\n",
    "len(emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметьте, что данные очень грязные. В каждом письме содержится различная мета-информация, которая будет только мешать при предсказании продолжения текста.\n",
    "\n",
    "__Задание 1 (1 балл).__ Очистите корпус текстов по вашему усмотрению. В идеале обработанные тексты должны содержать только текст самого письма и ничего лишнего по типу ссылок, адресатов и прочих символов, которыми мы точно не хотим продолжать текст. Оценка будет выставляться по близости вашего результата к этому идеалу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <10586305.1075855378285.JavaMail.evans@thyme>\n",
      "Date: Mon, 7 May 2001 16:23:00 -0700 (PDT)\n",
      "From: phillip.allen@enron.com\n",
      "To: stanley.horton@enron.com, dmccarty@enron.com\n",
      "Subject: California Summary\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: stanley.horton <stanley.horton@enron.com>, dmccarty <dmccarty@enron.com>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen (Non-Privileged).pst\n",
      "\n",
      "\n",
      "---------------------- Forwarded by Phillip K Allen/HOU/ECT on 05/07/2001 11:22 AM ---------------------------\n",
      "   \n",
      "\n",
      "\t  From:  Jay Reitmeyer                           05/03/2001 11:03 AM\t\n",
      "\t\t\n",
      "\n",
      "\n",
      "To:\tstanley.horton@enron.com, dmccarty@enron.com\n",
      "cc:\t \n",
      "Subject:\tCalifornia Summary\n",
      "\n",
      "Attached is the final version of the California Summary report with maps, graphs, and historical data.\n",
      "\n",
      "\n",
      " \n",
      "To:\tPhillip K Allen/HOU/ECT@ECT\n",
      "cc:\t \n",
      "bcc:\t\n",
      "Subject:\tAdditional California Load Information\n",
      "\n",
      "\n",
      "\n",
      "Additional charts attempting to explain increase in demand by hydro, load growth, and temperature.  Many assumptions had to be made.  The data is not as solid as numbers in first set of graphs.\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(emails.iloc[550,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсматривая сообщения руками, можно заметить, что метаданные отделяются от содержания* при помощи двойного переноса строки (\\n\\n).\n",
    "Поскольку метаданные нам вообще не нужны, мы можем начать с того, что просто их откинем для простоты дальнейшего препроцессинга.\n",
    "Да, двойной перенос строки будет еще в дальнейшем встречаться в тексте (особенно при переносе строк при обращениях внутри текста письма, например), но первый перенос строки точно предназначен для отделения метаданных.\n",
    "\n",
    "Но этого недостаточно для того, чтобы полностью отделить лишнее: помимо метаданных у нас останется еще доп. информация по пересылке письма (дата, время, получатель, отправитель)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отделяю содержание от метаданных по первому возникновению \\n\\n\n",
    "\n",
    "emails['message_wo_metadata'] = emails['message'].apply(lambda x: x.split('\\n\\n', 1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------- Forwarded by Phillip K Allen/HOU/ECT on 05/07/2001 11:22 AM ---------------------------\n",
      "   \n",
      "\n",
      "\t  From:  Jay Reitmeyer                           05/03/2001 11:03 AM\t\n",
      "\t\t\n",
      "\n",
      "\n",
      "To:\tstanley.horton@enron.com, dmccarty@enron.com\n",
      "cc:\t \n",
      "Subject:\tCalifornia Summary\n",
      "\n",
      "Attached is the final version of the California Summary report with maps, graphs, and historical data.\n",
      "\n",
      "\n",
      " \n",
      "To:\tPhillip K Allen/HOU/ECT@ECT\n",
      "cc:\t \n",
      "bcc:\t\n",
      "Subject:\tAdditional California Load Information\n",
      "\n",
      "\n",
      "\n",
      "Additional charts attempting to explain increase in demand by hydro, load growth, and temperature.  Many assumptions had to be made.  The data is not as solid as numbers in first set of graphs.\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(emails.iloc[550,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы отделили содержание писем: теперь, если письмо не форвардится никуда, то мы по сути получили то, что хотели - просто текст (останется привести все в нижний регистр и убрать пунктуацию), но если оно куда-то перенаправляется, остается много мусора, который тоже нужно убрать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замечаем, что самое последнее, что после метаданных пересылки встречается перед непосредственным содержанием письма, это 'Subject: Theme \\n\\n'.\n",
    "\n",
    "Используем это: отделим все, что находится левее самого последнего 'Subject: ', а потом отделим это по первому возникновению '\\n\\n', чтобы убрать тему, и получим текст без заголовка пересылки и самой пересылки.\n",
    "\n",
    "(Я думаю, в пересылках оставлять сам текст письма, на который человек отвечает, не очень уместно, так как у нас должен на выходе получиться подсказчик текста, который подсказывает текст исходя из того, что это отдельная законченная мысль от одного человека, а сохраняя разные ответы в одном тексте письма может случиться так, что подсказчик будет выдавать продолжения в формате диалога, что будет странно. Поэтому мне кажется, что лучше просто само письмо оставлять в результате препроцессинга, без ответов/пересылок.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------- Forwarded by Phillip K Allen/HOU/ECT on 05/07/2001 11:22 AM ---------------------------\n",
      "   \n",
      "\n",
      "\t  From:  Jay Reitmeyer                           05/03/2001 11:03 AM\t\n",
      "\t\t\n",
      "\n",
      "\n",
      "To:\tstanley.horton@enron.com, dmccarty@enron.com\n",
      "cc:\t \n",
      "Subject:\tCalifornia Summary\n",
      "\n",
      "Attached is the final version of the California Summary report with maps, graphs, and historical data.\n",
      "\n",
      "\n",
      " \n",
      "To:\tPhillip K Allen/HOU/ECT@ECT\n",
      "cc:\t \n",
      "bcc:\t\n",
      "Subject:\tAdditional California Load Information\n",
      "\n",
      "\n",
      "\n",
      "Additional charts attempting to explain increase in demand by hydro, load growth, and temperature.  Many assumptions had to be made.  The data is not as solid as numbers in first set of graphs.\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(emails.iloc[550,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заметила, что применять описанный алгоритм на все строки плохо, тк сплит по \\n\\n выкинет часть письма, если в \n",
    "# сообщении не было темы, так что написала функцию, чтобы сплит по \\n\\n был только тогда, когда у нас есть тема (есть форвард)\n",
    "\n",
    "def split_forward(msg):\n",
    "    \n",
    "    if 'Subject:' in msg:\n",
    "        return msg.rsplit('Subject:', 1)[-1].split('\\n\\n', 1)[-1]\n",
    "        \n",
    "    else:\n",
    "        return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails['message_wo_forward'] = emails['message_wo_metadata'].apply(lambda x: split_forward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for the information.  It would be helpful if you would send the \n",
      "detailed worksheet that you mentioned.\n",
      "\n",
      "I am surprised to hear that the only restricted shares left are the ones \n",
      "granted this January.  I have always elected to defer any distributions of \n",
      "restricted stock.  I believe I selected the minimum amount required to be \n",
      "kept in enron stock (50%).   Are you saying that all the previous grants have \n",
      "fully vested and been distributed to my deferral account?\n",
      "\n",
      "Thank you for looking into this issue.\n",
      "\n",
      "Phillip\n"
     ]
    }
   ],
   "source": [
    "print(emails.iloc[1003,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие у нас еще остаются проблемы с текстом? Из того, что я смогла заметить: ссылки, назначенные в функционале почты встречи (тоже содержат ненужные метаданные, как пересылки), прикрепленные файлы, а также лишние \\n, имейл адреса внутри писем, цифры (ими мы продолжать текст не будем, они будут только мешать - айпи адреса, время, даты, количества чего-то), пунктуация и спец сивмолы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сообщений, приложенных к встречам, немного, и они обычно следуют перед пересылкой встречи с разделителем '----------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails['message_wo_meetings'] = emails['message_wo_forward'].apply(lambda x: x.split('----------------------', 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сообщения с большим количеством получателей (15-20+) форматируются по-другому, у них после первой итерации препроцессинга не убрались метаданные, поэтому я очищаю их повторно, тем же способом, что и форварды, то есть отсекая тему и \\n\\n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails['message_wo_subscription_metadata'] = emails['message_wo_meetings'].apply(lambda x: split_forward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, все метаданные и детали функционала outlook вычищены (ответы, пересылки, встречи, детали массовой рассылки).\n",
    "Теперь уберем частные загрязнения: имейл адреса внутри текста писем, приложенные файлы и ссылки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove email addresses\n",
    "emails['message_wo_emails'] = emails['message_wo_subscription_metadata'].apply(lambda x: re.sub(r'\\S*@\\S*\\s?', '', x))\n",
    "\n",
    "# remove urls\n",
    "emails['message_wo_urls'] = emails['message_wo_emails'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "\n",
    "\n",
    "# remove attached files\n",
    "emails['message_wo_files'] = emails['message_wo_urls'].apply(lambda x: re.sub(r'-\\s\\S*.\\S*', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша финальная итерация препроцессинга: убираем цифры, пунктуацию, приводим все к одному регистру\n",
    "\n",
    "Обосную свое решение убрать пунктуацию тем, что с ней в целом будет сложно работать, и она будет создавать больше проблем, чем пользы:\n",
    "знаки пунктуации не зависят от смысловой нагрузки слова (в отличие от n-грамм, где фокус идет на то, что связанные по смыслу слова часто встречаются вместе), они проставляются механическими правилами, наша система не сможет их вставлять к месту, она просто будет вставлять запятую и точку после слова, которое чаще всего предшествовало запятой (это скорее всего будет какая-нибудь служебная часть речи) или заканчивало предложение. Если же мы отнесемся к пунктуации не как к отдельному токену, а как к последнему символу токена предыдущего слова, у нас получится по 2 слова на одну словоформу, что увеличит время работы программы, пространство необходимое для хранения данных, но не добавит смысла, потому что пунктация проставляется не только на основе предшествующих слов, но и на основе следующих (для обозначения противопоставления, для отделения законченной мысли и так далее), а у нас не учитывается дальнейший контекст в функционале. Более того, мы можем жадным способом предсказывать слово за словом, и несмотря на схожесть контекста и смысла токенов \"Х\" и \"Х,\", в словаре сразу сузится количество возможных слов после \"Х\", потому что оно будет зависеть от того, как часто оно встречалось рядом именно с запятой. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "\n",
    "    x_lowercase = x.lower()\n",
    "    x_no_digits = re.sub('\\d+', '', x_lowercase)\n",
    "    x_no_nextstring = x_no_digits.replace('\\n', ' ')\n",
    "    x_no_punctuation = re.sub(r'[^a-zA-Z\\s]', ' ', x_no_nextstring)\n",
    "    x_final = re.sub(' +', ' ', x_no_punctuation)\n",
    "\n",
    "    return x_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails['message_preprocessed'] = emails['message_wo_files'].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here is our forecast \n",
      "0\n",
      "traveling to have a business meeting takes the fun out of the trip especially if you have to prepare a presentation i would suggest holding the business plan meetings here then take a trip without any formal business meetings i would even try and get some honest opinions on whether a trip is even desired or necessary as far as the business meetings i think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not too often the presenter speaks and the others are quiet just waiting for their turn the meetings might be better if held in a round table discussion format my suggestion for where to go is austin play golf and rent a ski boat and jet ski s flying somewhere takes too much time \n",
      "1\n",
      "test successful way to go \n",
      "2\n",
      "randy can you send me a schedule of the salary and level of everyone in the scheduling group plus your thoughts on any changes that need to be made patti s for example phillip\n",
      "3\n",
      "let s shoot for tuesday at \n",
      "4\n",
      "greg how about either next tuesday or thursday phillip\n",
      "5\n",
      "please cc the following distribution list with updates phillip allen mike grigsby keith holst monique sanchez frank ermis john lavorato thank you for your help phillip allen \n",
      "6\n",
      "any morning between and \n",
      "7\n",
      " login pallen pw kedavis i don t think these are required by the isp static ip address ip sub gate dns company rc \n",
      "8\n",
      " phillip as discussed during our phone conversation in a parallon microturbine power generation deal for a national accounts customer i am developing a proposal to sell power to customer at fixed or collar floor price to do so i need a corresponding term gas price for same microturbine is an onsite generation product developed by honeywell to generate electricity on customer site degen using natural gas in doing so i need your best fixed price forward gas price deal for and years for annual seasonal supply to microturbines to generate fixed kwh for customer we have the opportunity to sell customer kwh s using microturbine or sell them turbines themselves kwh deal must have limited no risk forward gas price to make deal work therein comes sempra energy gas trading truly you we are proposing installing across a large number of stores in san diego store number varies because of installation hurdles face at small percent for hours a day microturbine run time gas requirement for microturbines per year gas requirement for microturbines per year gas will likely be consumed from may through september during peak electric period gas price required burnertip price behind ldc san diego gas electric need detail breakout of commodity and transport cost firm or interruptible should you have additional questions give me a call let me assure you this is real deal buck buckner p e mba manager business development and planning big box retail sales honeywell power systems inc pan american frwy albuquerque nm x \n",
      "9\n",
      "mr buckner for delivered gas behind san diego enron energy services is the appropriate enron entity i have forwarded your request to zarin imam at ees her phone number is phillip allen\n",
      "10\n",
      "lucy here are the rentrolls open them and save in the rentroll folder follow these steps so you don t misplace these files click on save as click on the drop down triangle under save in click on the c drive click on the appropriate folder click on save phillip\n",
      "11\n",
      " from our initial set of meetings with the traders regarding consolidated positions i think we still have the following issues we don t have a single point of contact from the trading group we ve had three meetings which brought out very different issues from different traders we really need a single point of contact to help drive the trader requirements and help come to a consensus regarding the requirements we re getting hit with a lot of different requests many of which appear to be outside the scope of position consolidation things left to do i think it may be useful to try to formulate a high level project goal to make it as clear as possible what we re trying to accomplish with this project it ll help determine which requests fall under the project scope go through the list of requests to determine which are in scope for this project and which fall out of scope for those in scope work to define relative importance priority of each and work with traders to define the exact requirements of each define the desired lay out of the position manager screen main view and all drill downs use the above to formulate a project plan things requested thus far no particular order inclusion of sitara physical deals into the tds position manager and deal ticker customized rows and columns in the position manager ad hoc rows columns that add up existing position manager rows columns new drill down in the position manager to break out positions by physical transport swaps options addition of a curve tab to the position manager to show the real time values of all curves on which the desk has a position ability to split the current position grid to allow daily positions to be shown directly above monthly positions each grouped column in the top grid would be tied to a grouped column in the bottom grid ability to properly show curve shift for float for float deals determine the appropriate positions to show for each gas daily for monthly index physical gas for nymex physical gas for inside ferc physical gas for mid market ability for tds to pull valuation results based on a tds flag instead of using official valuations position and p l aggregation across all gas desks ability to include the gas price book into tds inclusion of spread options in our systems ability to handle volatility skew and correlations ability to revalue all options incrementally throughout the trading day approximate delta changes between valuations using instantaneous gamma or a gamma grid valuation of gas daily options a new position screen for options months x strike x delta tbd inclusion of positions for exotic options currently managed in spreadsheets ability to isolate the position change due to changed deals in the position manager ability to view change deal p l in the tds deal ticker show new deal terms prior deal terms and net p l affect of the change eliminate change deals with no economic impact from the tds deal ticker position drill down in the position manager to isolate the impact of individual deals on the position total in a grid cell benchmark positions in tds deployment of tds in canada currency and volume uom conversions implicit and explicit position break out issues ps colleen is setting up a meeting tomorrow to discuss the direction for transport hopefully we ll know much better where that part stands at that point \n",
      "12\n",
      " from our initial set of meetings with the traders regarding consolidated positions i think we still have the following issues we don t have a single point of contact from the trading group we ve had three meetings which brought out very different issues from different traders we really need a single point of contact to help drive the trader requirements and help come to a consensus regarding the requirements we re getting hit with a lot of different requests many of which appear to be outside the scope of position consolidation things left to do i think it may be useful to try to formulate a high level project goal to make it as clear as possible what we re trying to accomplish with this project it ll help determine which requests fall under the project scope go through the list of requests to determine which are in scope for this project and which fall out of scope for those in scope work to define relative importance priority of each and work with traders to define the exact requirements of each define the desired lay out of the position manager screen main view and all drill downs use the above to formulate a project plan things requested thus far no particular order inclusion of sitara physical deals into the tds position manager and deal ticker customized rows and columns in the position manager ad hoc rows columns that add up existing position manager rows columns new drill down in the position manager to break out positions by physical transport swaps options addition of a curve tab to the position manager to show the real time values of all curves on which the desk has a position ability to split the current position grid to allow daily positions to be shown directly above monthly positions each grouped column in the top grid would be tied to a grouped column in the bottom grid ability to properly show curve shift for float for float deals determine the appropriate positions to show for each gas daily for monthly index physical gas for nymex physical gas for inside ferc physical gas for mid market ability for tds to pull valuation results based on a tds flag instead of using official valuations position and p l aggregation across all gas desks ability to include the gas price book into tds inclusion of spread options in our systems ability to handle volatility skew and correlations ability to revalue all options incrementally throughout the trading day approximate delta changes between valuations using instantaneous gamma or a gamma grid valuation of gas daily options a new position screen for options months x strike x delta tbd inclusion of positions for exotic options currently managed in spreadsheets ability to isolate the position change due to changed deals in the position manager ability to view change deal p l in the tds deal ticker show new deal terms prior deal terms and net p l affect of the change eliminate change deals with no economic impact from the tds deal ticker position drill down in the position manager to isolate the impact of individual deals on the position total in a grid cell benchmark positions in tds deployment of tds in canada currency and volume uom conversions implicit and explicit position break out issues ps colleen is setting up a meeting tomorrow to discuss the direction for transport hopefully we ll know much better where that part stands at that point \n",
      "13\n",
      "dave here are the names of the west desk members by category the origination side is very sparse phillip \n",
      "14\n",
      "paula million is fine phillip\n",
      "15\n",
      "please plan to attend the below meeting topic var reporting and resources meeting date wednesday october th time location ebc if you have any questions conflicts please feel free to call me thanks rain x \n",
      "16\n",
      "tim mike grigsby is having problems with accessing the west power site can you please make sure he has an active password thank you phillip\n",
      "17\n",
      " westgate enclosed are demographics on the westgate site from investor s alliance investor s alliance says that these demographics are similar to the package on san marcos that you received earlier if there are any other questions or information requirements let me know then let me know your interest level in the westgate project san marcos the property across the street from the sagewood units in san marcos is for sale and approved for units the land is selling for per square foot as it is one of only two remaining approved multifamily parcels in west san marcos which now has a moratorium on development several new studies we have looked at show that the rents for our duplexes and for these new units are going to be significantly higher roughly per square foot if leased for the entire unit on a month lease and psf if leased on a month term but by individual room this property will have the best location for student housing of all new projects just as the duplexes do now if this project is of serious interest to you please let me know as there is a very very short window of opportunity the equity requirement is not yet known but it would be likely to be to secure the land i will know more on this question later today sincerely george w richards president creekside builders llc \n",
      "18\n",
      "there will be a meeting on tuesday oct th at pm in eb regarding storage strategies in the west please mark your calendars thank you regards nancy hall ena denver office \n",
      "19\n",
      "brenda please use the second check as the october payment if you have already tossed it let me know so i can mail you another phillip\n",
      "20\n",
      "i think fletch has a good cpa i am still doing my own \n",
      "21\n",
      "brenda please use the second check as my october payment i have my copy of the original deal do you want me to fax this to you phillip\n",
      "22\n",
      "\n",
      "23\n",
      "liane as we discussed yesterday i am concerned there has been an attempt to manipulate the el paso san juan monthly index a single buyer entered the marketplace on both september and and paid above market prices for san juan gas with the intent to distort the index at the time of these trades offers for physical gas at significantly to cents lower prices were bypassed in order to establish higher trades to report into the index calculation additionally these trades are out of line with the associated financial swaps for san juan we have compiled a list of financial and physical trades executed from september to september these are the complete list of trades from enron online eol enron s direct phone conversations and three brokerage firms amerex apb and prebon please see the attached spreadsheet for a trade by trade list and a summary we have also included a summary of gas daily prices to illustrate the value of san juan based on several spread relationships the two key points from this data are as follows the high physical prices on the th th are much greater than the high financial trades on those days the spread relationship between san juan and other points socal northwest is consistent between the end of september and october gas daily it doesn t make sense to have monthly indeces that are dramatically different i understand you review the trades submitted for outliers hopefully the trades submitted will reveal counterparty names and you will be able to determine that there was only one buyer in the s and these trades are outliers i wanted to give you some additional points of reference to aid in establishing a reasonable index it is enron s belief that the trades at and higher were above market trades that should be excluded from the calculation of index it is our desire to have reliable and accurate indeces against which to conduct our physical and financial business please contact me anytime i can assist you towards this goal sincerely phillip allen \n",
      "24\n",
      " structure typically the structure is a limited partnership with a corporate or llc general partner the general partner owns of the project and carries the liability of construction land ownership loans the property would be purchased in the name of the limited partnership and any land loans land improvements loans and construction loans would be in the name of the limited partnership each of the individual investors and all of the principals in creekside would also personally guarantee the loans if the investor s do not sign on the loans this generally means that a larger amount of cash is required and the investor s share of profits is reduced all loans for residential construction that are intended for re sale are full recourse loans if we are pursuing multifamily rental developments the construction loans are still full recourse but the mortgage can often be non recourse use of initial investment the initial investment is used for land deposit engineering architectural design soils tests surveys filing fees legal fees for organization and condominium association formation and appraisals unlike many real estate investment programs none of the funds are used for fees to creekside builders llc these professional expenses will be incurred over the estimated month design and approval period early land costs the per month costs listed in the cash flow as part of land cost represent the extension fees due to the seller for up to months of extensions on closing as an alternative we can close into a land loan at probably of appraised value with a land value equal to the purchase price of this would mean a land loan of with estimated monthly interest payments of given a annual interest rate plus approximately of the loan amount for closing costs and loan fees equity at improvement loan once the site plan is approved by the city of austin the city will require the development entity to post funds for fiscal improvements referred to as the fiscals this cost represents a bond for the completion of improvements that coa considers vital and these funds are released once the improvements have been completed and accepted by coa this release will be for of the cost with the remaining released one year after completion releases can be granted once every days and you should expect that the release would occur months after the start of lot improvement construction these fiscals are usually posted in cash or an irrevocable letter of credit as such they have to be counted as a development cost even though they are not spent because they are not spent no interest is charged on these funds the lot improvement loan is typically of the appraised value of a finished lot which i suspect will be at least and potentially as high as this would produce a loan amount of on per lot with estimated per lot improvement costs of fiscals at and the land cost at total improved lot cost is which means to per lot in total equity the investment prior to obtaining the improvement loan would count towards any equity requirement provided it was for direct costs thus the additional equity for the improvement loan would be even if the maximum loan would cover all costs it is unlikely the bank would allow reimbursement of funds spent the higher estimates of equity investments are shown in the preliminary proforma to be on the safe side the engineer is preparing a tentative site layout with an initial evaluation of the phasing which can significantly reduce the cash equity requirement phasing works as follows if the first phase was say units the total lot improvement cost might average per lot of this probably would be for improvements and for the land cost the improvements are higher to cover large one time up front costs for design costs the entry road water treatment costs perimeter fencing and landscaping and so on as well as for of the land the land loan for undeveloped lots would be of the appraised raw lot value which i would estimate as per lot for a loan value of per lot then the loan value for each improved lot would be per lot this would give you a total loan of total cost of for equity required of this was not presented in the initial analysis as the phasing is depended on a more careful assessment by the civil engineer as the separate phases must each be able to stand on its own from a utility standpoint construction loans there are three types of construction loans first is a speculative spec loan that is taken out prior to any pre sales activity second is a construction loan for a pre sold unit but the loan remains in the builder developers name third is a pre sold unit with the construction loan in the name of the buyer we expect to have up to spec loans to start the project and expect all other loans to be pre sold units with loans in the name of the builder developer we do not expect to have any construction loans in the name of the buyers as such loans are too difficult to manage and please new buyers unfamiliar with the process spec loans will be for to of value and construction loans for pre sold units if the construction loan is from the mortgage lender will be from to of value disbursements disbursements will be handled by the general partner to cover current and near term third party costs then to necessary reserves then to priority payments and then to the partners per the agreement the general partner will contract with creekside builders llc to construct the units and the fee to cb will include a construction management and overhead fee equal to of the direct hard cost excluding land financing and sales costs these fees are the only monies to creekside larry lewter or myself prior to calculation of profit except for a direct reimbursement for partnership expenses and b direct payment to cb for any subcontractor costs that it has to perform for example if cb cannot find a good trim carpenter sub or cannot find enough trim carpenters etc and it decides to undertake this function it will charge the partnership the same fee it was able to obtain from third parties and will disclose those cases to the partnership finally cb will receive a fee for the use of any of its equipment if it is used in lieu of leasing equipment from others at present cb does not own any significant equipment but it is considering the purchase of a sky track to facilitate and speed up framing cornice roofing and drywall spreading reporting we are more than willing to provide reports to track expenses vs plan what did you have in mind i would like to use some form of internet based reporting bookkeeping i am not sure what you are referring to by the question bookkeeping procedures to record actual expenses please expand investor input we are glad to have the investor s input on design and materials as always the question will be who has final say if there is disagreement but in my experience i have always been able to reach consensus as you and i presume keith want to be involved to learn as much as possible we would make every effort to be accommodating creekside proceedures cb procedures for dealing with subs vendors and professionals is not as formal as your question indicates in the extremely tight labor market obtaining bids for each labor trade is not feasible for the professional subs we use those with whom we have developed a previous rapport finally for vendors they are constantly shopped pre selected professionals subs and vendors yes there are many different subs that have been identified and i can provide these if you are interested i know i have not answered everything but this is a starting point call when you have reviewed and we can discuss further sincerely george richards president creekside builders llc \n",
      "25\n",
      " structure typically the structure is a limited partnership with a corporate or llc general partner the general partner owns of the project and carries the liability of construction land ownership loans the property would be purchased in the name of the limited partnership and any land loans land improvements loans and construction loans would be in the name of the limited partnership each of the individual investors and all of the principals in creekside would also personally guarantee the loans if the investor s do not sign on the loans this generally means that a larger amount of cash is required and the investor s share of profits is reduced all loans for residential construction that are intended for re sale are full recourse loans if we are pursuing multifamily rental developments the construction loans are still full recourse but the mortgage can often be non recourse use of initial investment the initial investment is used for land deposit engineering architectural design soils tests surveys filing fees legal fees for organization and condominium association formation and appraisals unlike many real estate investment programs none of the funds are used for fees to creekside builders llc these professional expenses will be incurred over the estimated month design and approval period early land costs the per month costs listed in the cash flow as part of land cost represent the extension fees due to the seller for up to months of extensions on closing as an alternative we can close into a land loan at probably of appraised value with a land value equal to the purchase price of this would mean a land loan of with estimated monthly interest payments of given a annual interest rate plus approximately of the loan amount for closing costs and loan fees equity at improvement loan once the site plan is approved by the city of austin the city will require the development entity to post funds for fiscal improvements referred to as the fiscals this cost represents a bond for the completion of improvements that coa considers vital and these funds are released once the improvements have been completed and accepted by coa this release will be for of the cost with the remaining released one year after completion releases can be granted once every days and you should expect that the release would occur months after the start of lot improvement construction these fiscals are usually posted in cash or an irrevocable letter of credit as such they have to be counted as a development cost even though they are not spent because they are not spent no interest is charged on these funds the lot improvement loan is typically of the appraised value of a finished lot which i suspect will be at least and potentially as high as this would produce a loan amount of on per lot with estimated per lot improvement costs of fiscals at and the land cost at total improved lot cost is which means to per lot in total equity the investment prior to obtaining the improvement loan would count towards any equity requirement provided it was for direct costs thus the additional equity for the improvement loan would be even if the maximum loan would cover all costs it is unlikely the bank would allow reimbursement of funds spent the higher estimates of equity investments are shown in the preliminary proforma to be on the safe side the engineer is preparing a tentative site layout with an initial evaluation of the phasing which can significantly reduce the cash equity requirement phasing works as follows if the first phase was say units the total lot improvement cost might average per lot of this probably would be for improvements and for the land cost the improvements are higher to cover large one time up front costs for design costs the entry road water treatment costs perimeter fencing and landscaping and so on as well as for of the land the land loan for undeveloped lots would be of the appraised raw lot value which i would estimate as per lot for a loan value of per lot then the loan value for each improved lot would be per lot this would give you a total loan of total cost of for equity required of this was not presented in the initial analysis as the phasing is depended on a more careful assessment by the civil engineer as the separate phases must each be able to stand on its own from a utility standpoint construction loans there are three types of construction loans first is a speculative spec loan that is taken out prior to any pre sales activity second is a construction loan for a pre sold unit but the loan remains in the builder developers name third is a pre sold unit with the construction loan in the name of the buyer we expect to have up to spec loans to start the project and expect all other loans to be pre sold units with loans in the name of the builder developer we do not expect to have any construction loans in the name of the buyers as such loans are too difficult to manage and please new buyers unfamiliar with the process spec loans will be for to of value and construction loans for pre sold units if the construction loan is from the mortgage lender will be from to of value disbursements disbursements will be handled by the general partner to cover current and near term third party costs then to necessary reserves then to priority payments and then to the partners per the agreement the general partner will contract with creekside builders llc to construct the units and the fee to cb will include a construction management and overhead fee equal to of the direct hard cost excluding land financing and sales costs these fees are the only monies to creekside larry lewter or myself prior to calculation of profit except for a direct reimbursement for partnership expenses and b direct payment to cb for any subcontractor costs that it has to perform for example if cb cannot find a good trim carpenter sub or cannot find enough trim carpenters etc and it decides to undertake this function it will charge the partnership the same fee it was able to obtain from third parties and will disclose those cases to the partnership finally cb will receive a fee for the use of any of its equipment if it is used in lieu of leasing equipment from others at present cb does not own any significant equipment but it is considering the purchase of a sky track to facilitate and speed up framing cornice roofing and drywall spreading reporting we are more than willing to provide reports to track expenses vs plan what did you have in mind i would like to use some form of internet based reporting bookkeeping i am not sure what you are referring to by the question bookkeeping procedures to record actual expenses please expand investor input we are glad to have the investor s input on design and materials as always the question will be who has final say if there is disagreement but in my experience i have always been able to reach consensus as you and i presume keith want to be involved to learn as much as possible we would make every effort to be accommodating creekside proceedures cb procedures for dealing with subs vendors and professionals is not as formal as your question indicates in the extremely tight labor market obtaining bids for each labor trade is not feasible for the professional subs we use those with whom we have developed a previous rapport finally for vendors they are constantly shopped pre selected professionals subs and vendors yes there are many different subs that have been identified and i can provide these if you are interested i know i have not answered everything but this is a starting point call when you have reviewed and we can discuss further sincerely george richards president creekside builders llc \n",
      "26\n",
      "this meeting has been moved to on wed in room i have sent a confirmation to each of you via lotus notes sorry for all of the changes but there was a scheduling problem with a couple of people for the original time slot \n",
      "27\n",
      "reagan just wanted to give you an update i have changed the unit mix to include some bedrooms and reduced the number of buildings to kipp flores is working on the construction drawings at the same time i am pursuing fha financing once the construction drawings are complete i will send them to you for a revised bid your original bid was competitive and i am still attracted to your firm because of your strong local presence and contacts phillip\n",
      "28\n",
      "nymex expiration is during this time frame please reschedule \n",
      "29\n",
      "\n",
      "30\n",
      "i have scheduled and entered on each of your calendars a meeting for the above referenced topic it will take place on thursday from in room eb \n",
      "31\n",
      " jeff is the closing today after reviewing the agreement i find it isn t binding as far as i can determine it is too vague and it doesn t sound like anything an attorney or title company would draft for a real estate closing but of course i could be wrong if this closing is going to take place without this agreement then there is no point in me following up on this document s validity i will just need to go back to my closing documents and see what s there and find out where i am with that and deal with this as best i can i guess i was expecting something that would be an exhibit to a recordable document or something a little more exact or rather sort of a contract this isn t either i tried to get a real estate atty on the phone last night but he was out of pocket i talked to a crim atty friend and he said this is out of his area but doesn t sound binding to him i will go back to mine and phillip allen s transaction and take a look at that but as vague and general as this is i doubt that my signature is even needed to complete this transaction i am in after noon if there is any need to contact me regarding the closing i really do not want to hold up anything or generate more work for myself and i don t want to insult or annoy anyone but this paper really doesn t seem to be something required for a closing in the event you do need my signature on something like this i would rather have time to have it reviewed before i accept it brenda \n",
      "32\n",
      "chris what is the latest with pg e we have been having good discussions regarding eol call me when you can x phillip\n",
      "33\n",
      "\n",
      "34\n",
      "\n",
      "35\n",
      "greg happy b day email me your phone and i will call you keith\n",
      "36\n",
      "kathy regarding the guest password for gas daily can you please relay the information to mike grigsby at so he can pass it along to the user at gas daily today i will be out of the office on friday thank you phillip\n",
      "37\n",
      "john denver s short rockies position beyond is created by their trailblazer transport they are unhedged d in and d in and they are scrubbing all their books and booking the hubert deal on wednesday and thursday phillip\n",
      "38\n",
      "jim is there going to be a conference call or some type of weekly meeting about all the regulatory issues facing california this week can you make sure the gas desk is included phillip\n",
      "39\n",
      "george below is a list of questions that keith and i had regarding the westgate project ownership structure what will be the ownership structure limited partnership general partner what are all the legal entities that will be involved and in what capacity regarding ownership and liabilities who owns the land improvements who holds the various loans is the land collateral investment what happens to initial investment is it used to purchase land for cash secure future loans why is the land cost spread out on the cash flow statement when is the actually needed now or for the land closing investment schedule investment return is equity repayment the return of the original investment is the plan to wait until the last unit is sold and closed before profits are distributed debt which entity is the borrower for each loan and what recourse or collateral is associated with each loan improvement construction are these the only two loans looks like it from the cash flow statement terms of each loan uses of funds how will disbursements be made by whom what type of bank account controls on max disbursement internet viewing for investors reports to track expenses vs plan bookkeeping procedures to record actual expenses what is the relationship of creekside builders to the project do you get paid a markup on subcontractors as a general contractor and paid gain out of profits do you or larry receive any money in the form of salary or personal expenses before the ultimate payout of profits design and construction when will design be complete what input will investors have in selecting design and materials for units what level of investor involvement will be possible during construction planning and permitting does creekside have specific procedures for dealing with subcontractors vendors and other professionals such as always getting bids payment schedules or reference checking are there any specific companies or individuals that you already plan to use names these questions are probably very basic to you but as a first time investor in a project like this it is new to me also i want to learn as much as possible from the process phillip \n",
      "40\n",
      " enclosed is the preliminary proforma for the westgate property is austin that we told you about as you can tell from the proforma this project should produce a truly exceptional return of over per year over years this is especially attractive when the project is in a market as strong as austin and we are introducing new product that in a very low price range for this market this is the best project in terms of risk and reward that we have uncovered to date in the austin market the project does have approved zoning and will only require a site plan as it is in the smart growth corridor area designated by the city of austin for preferred development this will be fast tracked and should be complete in less than months additionally many of the current and more severe water treatment ordinances have been waived i have estimated the lot improvement costs based on a lot development we investigated in north austin which included a detention retention and filtration pond and street widening even though this property is not likely to require street widening and will have less of a detention retention and filtration pond requirement i used this data to be cautious the lone star gas line easement in the lower portion of the property is not expected to impact sales significantly other projects have been quite successful with identical relationships to this pipeline such as the adjoining single family residential and a project at st edwards university as with most infill projects the quality of the surrounding neighborhoods is uneven we have included a fence around the entire property but may only put it on westgate and cameron loop gated communities are far preferred so this is a good idea for both screening and current buyer preferences the seller accepted our offer thursday evening with a price of and an extended escrow this will enable us to probably obtain an approved site plan before closing on the contract which will mean that we can close into an a d loan rather than into a land loan and then an improvement loan this analysis shows your investment at for a interest in the profits of the project as we discussed in san marcos we can also discuss having you invest only in the lots sell the lots to the construction entity with your profit in the lot i believe this would facilitate the use of a exchange of the proceeds from this deal into another project that is a rental deal or at least into the land for a rental project that would then be the equity for that project you would need to discuss this with an exchange expert first larry lewter knows an expert in the field in san antonio if you do not know anyone i will send you a package on the property that was prepared by the broker by airborne express today for saturday delivery once you have read the package and reviewed this proforma we would want to schedule a tour of the site and the area please get back to me as soon as your schedule permits regarding the site visit and feel free to call at any time you can reach me over the weekend and in the evening at either or my cell phone is and the fax is i look forward to hearing from you and to working with you on this project that is sure to be a major winner i regret that it took so long to get back to you but we had some unusual events these past few weeks a small freakish wind storm with severe mpg downdrafts hit the south part of austin where we are building town homes one of these units had just had the roof decked with the siding scheduled to start the next day the severe downdraft hitting the decked roof was enough to knock it down the city shut down the project for a week and it took another week to get every thing back on tract then last week i had to take my wife to emergency she has a bulge in the material between the vertebra in her spine and it causes her extreme pain and has kept her bedridden this past week there is nothing like having your wife incapacitated to realize the enormous number of things she does everyday fortunately it looks as if she will be ok in the long run george w richards creekside builders llc allen xls \n",
      "41\n",
      "george here sales numbers from reagan as you can see his units sold at a variety of prices per square foot the model seems to have the most data and looks most similiar to the units you are selling at mm my bid is sf higher than his units under construction i am having a hard time justifying paying much more with competition on the way the price i am bidding is higher than any deals actually done to date let me know what you think i will follow up with an email and phone call about cherry creek i am sure deborah yates let you know that the bid was rejected on the de ville property phillip allen \n",
      "42\n",
      "jeff what is up with burnet phillip\n",
      "43\n",
      "jeff i need to see the site plan for burnet remember i must get written approval from brenda key stone before i can sell this property and she has concerns about the way the property will be subdivided i would also like to review the closing statements as soon as possible phillip\n",
      "44\n",
      "lucy i want to have an accurate rent roll as soon as possible i faxed you a copy of this file you can fill in on the computer or just write in the correct amounts and i will input \n",
      "45\n",
      "brenda i checked my records and i mailed check for the normal amount on august th i mailed it to pate rd college station tx i will go ahead and mail you another check if the first one shows up you can treat the nd as payment for october i know your concerns about the site plan i will not proceed without getting the details and getting your approval i will find that amortization schedule and send it soon phillip\n",
      "46\n",
      "lucy you wrote fewer checks this month spent more money on materials and less on labor june july august total materials services labor here are my questions on the august bank statement attached check walmart description and unit check crumps detail description and unit check lucy what is this check papes detail description and units checks and why overtime check ralph s what unit check walmart description and unit try and pull together the support for these items and get back to me phillip\n",
      "47\n",
      "phillip attached is the list have your people fill in the columns highlighted in yellow as best can we will try not to overlap on accounts thanks mike \n",
      "48\n",
      "\n",
      "49\n",
      " phillip allen login id \tpallen extension office location ebc what type of computer do you have desktop laptop both both do you have a pda if yes what type do you have none ipaq palm pilot jornada ipaq do you have permission to access anyone s email calendar no if yes who does anyone have permission to access your email calendar yes if yes who ina rangel are you responsible for updating anyone else s address book if yes who no is anyone else responsible for updating your address book if yes who no do you have access to a shared calendar if yes which shared calendar yes west calendar do you have any distribution groups that messaging maintains for you for mass mailings if yes please list here no please list all notes databases applications that you currently use none in our efforts to plan the exact date time of your migration we also will need to know what are your normal work hours from am to pm will you be out of the office in the near future for vacation leave etc no if so when from mm dd yy to mm dd yy embedded stdolelink \n",
      "50\n",
      " enclosed is the preliminary proforma for the westgate property is austin that we told you about as you can tell from the proforma this project should produce a truly exceptional return of over per year over years this is especially attractive when the project is in a market as strong as austin and we are introducing new product that in a very low price range for this market this is the best project in terms of risk and reward that we have uncovered to date in the austin market the project does have approved zoning and will only require a site plan as it is in the smart growth corridor area designated by the city of austin for preferred development this will be fast tracked and should be complete in less than months additionally many of the current and more severe water treatment ordinances have been waived i have estimated the lot improvement costs based on a lot development we investigated in north austin which included a detention retention and filtration pond and street widening even though this property is not likely to require street widening and will have less of a detention retention and filtration pond requirement i used this data to be cautious the lone star gas line easement in the lower portion of the property is not expected to impact sales significantly other projects have been quite successful with identical relationships to this pipeline such as the adjoining single family residential and a project at st edwards university as with most infill projects the quality of the surrounding neighborhoods is uneven we have included a fence around the entire property but may only put it on westgate and cameron loop gated communities are far preferred so this is a good idea for both screening and current buyer preferences the seller accepted our offer thursday evening with a price of and an extended escrow this will enable us to probably obtain an approved site plan before closing on the contract which will mean that we can close into an a d loan rather than into a land loan and then an improvement loan this analysis shows your investment at for a interest in the profits of the project as we discussed in san marcos we can also discuss having you invest only in the lots sell the lots to the construction entity with your profit in the lot i believe this would facilitate the use of a exchange of the proceeds from this deal into another project that is a rental deal or at least into the land for a rental project that would then be the equity for that project you would need to discuss this with an exchange expert first larry lewter knows an expert in the field in san antonio if you do not know anyone i will send you a package on the property that was prepared by the broker by airborne express today for saturday delivery once you have read the package and reviewed this proforma we would want to schedule a tour of the site and the area please get back to me as soon as your schedule permits regarding the site visit and feel free to call at any time you can reach me over the weekend and in the evening at either or my cell phone is and the fax is i look forward to hearing from you and to working with you on this project that is sure to be a major winner i regret that it took so long to get back to you but we had some unusual events these past few weeks a small freakish wind storm with severe mpg downdrafts hit the south part of austin where we are building town homes one of these units had just had the roof decked with the siding scheduled to start the next day the severe downdraft hitting the decked roof was enough to knock it down the city shut down the project for a week and it took another week to get every thing back on tract then last week i had to take my wife to emergency she has a bulge in the material between the vertebra in her spine and it causes her extreme pain and has kept her bedridden this past week there is nothing like having your wife incapacitated to realize the enormous number of things she does everyday fortunately it looks as if she will be ok in the long run george w richards creekside builders llc allen xls \n",
      "51\n",
      "jeff i received the rent roll i am going to be in san marcos this weekend but i am booked with stage coach i will drive by friday evening i will let you know next week if i need to see the inside can you find out when chelsea villa last changed hands and for what price what about getting a look at the site plans for the burnet deal remember we have to get brenda happy phillip\n",
      "52\n",
      " diff socal nwpl san juan the reason the benchmark report shows net selling san juan is that the transport positions were rolled in on this added shorts to san juan and longs to socal before this adjustment we bought san juan and sold socal \n",
      "53\n",
      "why is aeco basis so low on the list is nwpl mapped differently than aeco what about the correlation to nymex on aeco \n",
      "54\n",
      "jeff you would clearly receive a commission on a deal on the sagewood i am surprised by your request for payment on any type of project in which i might become involved with creekside are you in the business of brokering properties or contacts is your position based on a legal or what you perceive to be an ethical issue did you propose we look at developing a project from scratch i am not prepared to pay more than for sagewood yet phillip\n",
      "55\n",
      " i was aware that regan lehman the lot developer for the entire lot duplex project was selling his units in the s he does have a much lower basis in the lots than anyone else but the prime differences are due to a he is selling them during construction and b they are smaller units we do not know the exact size of each of his units but we believe one of the duplexes is a sq ft plan this would produce an average sq footage of which would be psf at i thought his sales price was at this price psf our sf unit would sell for what is more important in my view is a the rental rate and b the rent ability you have all of our current rental and cost data for your own evaluation as for rent ability i believe that we have shown that the bedroom bath is strongly preferred in this market in fact if we were able to purchase additional lots from regan we would build bedroom units along with the bedroom plan phillip i will call you today to go over this more thoroughly sincerely george w richards creekside builders llc \n",
      "56\n",
      " enclosed is the preliminary proforma for the westgate property is austin that we told you about as you can tell from the proforma this project should produce a truly exceptional return of over per year over years this is especially attractive when the project is in a market as strong as austin and we are introducing new product that in a very low price range for this market this is the best project in terms of risk and reward that we have uncovered to date in the austin market the project does have approved zoning and will only require a site plan as it is in the smart growth corridor area designated by the city of austin for preferred development this will be fast tracked and should be complete in less than months additionally many of the current and more severe water treatment ordinances have been waived i have estimated the lot improvement costs based on a lot development we investigated in north austin which included a detention retention and filtration pond and street widening even though this property is not likely to require street widening and will have less of a detention retention and filtration pond requirement i used this data to be cautious the lone star gas line easement in the lower portion of the property is not expected to impact sales significantly other projects have been quite successful with identical relationships to this pipeline such as the adjoining single family residential and a project at st edwards university as with most infill projects the quality of the surrounding neighborhoods is uneven we have included a fence around the entire property but may only put it on westgate and cameron loop gated communities are far preferred so this is a good idea for both screening and current buyer preferences the seller accepted our offer thursday evening with a price of and an extended escrow this will enable us to probably obtain an approved site plan before closing on the contract which will mean that we can close into an a d loan rather than into a land loan and then an improvement loan this analysis shows your investment at for a interest in the profits of the project as we discussed in san marcos we can also discuss having you invest only in the lots sell the lots to the construction entity with your profit in the lot i believe this would facilitate the use of a exchange of the proceeds from this deal into another project that is a rental deal or at least into the land for a rental project that would then be the equity for that project you would need to discuss this with an exchange expert first larry lewter knows an expert in the field in san antonio if you do not know anyone i will send you a package on the property that was prepared by the broker by airborne express today for saturday delivery once you have read the package and reviewed this proforma we would want to schedule a tour of the site and the area please get back to me as soon as your schedule permits regarding the site visit and feel free to call at any time you can reach me over the weekend and in the evening at either or my cell phone is and the fax is i look forward to hearing from you and to working with you on this project that is sure to be a major winner i regret that it took so long to get back to you but we had some unusual events these past few weeks a small freakish wind storm with severe mpg downdrafts hit the south part of austin where we are building town homes one of these units had just had the roof decked with the siding scheduled to start the next day the severe downdraft hitting the decked roof was enough to knock it down the city shut down the project for a week and it took another week to get every thing back on tract then last week i had to take my wife to emergency she has a bulge in the material between the vertebra in her spine and it causes her extreme pain and has kept her bedridden this past week there is nothing like having your wife incapacitated to realize the enormous number of things she does everyday fortunately it looks as if she will be ok in the long run george w richards creekside builders llc allen xls \n",
      "57\n",
      " get your private free e mail from msn hotmail at share information about yourself create your own public profile at \n",
      "58\n",
      " executive impact influence program immediate action required delete as part of the executive impact and influence program each participant is asked to gather input on the participant s own management styles and practices as experienced by their immediate manager each direct report and up to eight peers colleagues you have been requested to provide feedback for a participant attending the next program your input i e a self assessment manager assessment direct report assessment or peer colleague assessment will be combined with the input of others and used by the program participant to develop an action plan to improve his her management styles and practices it is important that you complete this assessment no later than close of business thursday september since the feedback is such an important part of the program the participant will be asked to cancel his her attendance if not enough feedback is received therefore your feedback is critical to complete your assessment please click on the following link or simply open your internet browser and go to your unique id for each participant you have been asked to rate is unique id evhjy erfx epexwx if you experience technical problems please call dennis ward at fsd data services if you have any questions about this process you may contact debbie nowak at enron or christi smith at keilty goldsmith company thank you for your participation \n",
      "59\n",
      "larry just a note to touch base on the sagewood townhomes and other development opportunities i stumbled across some other duplexes for sale on the same street that were built by reagan lehmann units were sold for around million duplex i spoke to reagan and he indicated that he had more units under construction that would be available in the s are the units he is selling significantly different from yours he mentioned some of the units are the floor plan my bid of million is almost duplex as far as being an investor in a new project i am still very interested call or email with your thoughts phillip\n",
      "60\n",
      " current notes user reasons for using outlook web access owa once your mailbox has been migrated from notes to outlook the outlook c lient will be configured on your computer after migration of your mailbox you will not be able to send or recieve ma il via notes and you will not be able to start using outlook until it is c onfigured by the outlook migration team the morning after your mailbox is m igrated during this period you can use outlook web access owa via your web browser internet explorer to read and send mail please note your calendar entries personal address book journals and t o do entries imported from notes will not be available until the outlook cl ient is configured on your desktop remote access to your mailbox after your outlook client is configured you can use outlook web access ow a for remote access to your mailbox please note at this time the owa client is only accessible while connect ing to the enron network lan there are future plans to make owa availab le from your home or when traveling abroad how to access outlook web access owa launch internet explorer and in the address window type msowap exchange john doe substitute john doe with your first and last name then click enter you will be prompted with a sign in box as shown below type in corp your us er id for the user name and your nt password to logon to owa and click ok you will now be able to view your mailbox please note there are some subtle differences in the functionality betwee n the outlook and owa clients you will not be able to do many of the thin gs in owa that you can do in outlook below is a brief list of some of t he functions not available via owa features not available using owa checker use templates delivery rules message flags and message recall contacts with others delegation resource booking distribution lists questions or concerns if you have questions or concerns using the owa client please contact the outlook question and answer mailbox at otherwise you may contact the resolution center at thank you outlook migration team \n",
      "61\n",
      "ina i scheduled a meeting with jean mrha tomorrow at \n",
      "62\n",
      "internet data gain is a major power drain on local utilities september in a little known silicon valley company called exodus communications opened a square foot data center in tukwila the mission was to handle the internet traffic and computer servers for the region s growing number of dot coms fast forward to summer exodus is now wrapping up construction on a new acre square foot data center less than a mile from its original facility sitting at the confluence of several fiber optic backbones the exodus plant will consume enough power for a small town and eventually house internet servers for firms such as avenue a microsoft and onvia com exodus is not the only company building massive data centers near seattle more than a dozen companies like abovenet globix and hostpro for facilities here that will house the networking equipment of the internet economy it is a big business that could have an effect on everything from your monthly electric bill to the ease with which you access your favorite web sites data centers also known as co location facilities and server farms are sprouting at such a furious pace in tukwila and the kent valley that some have expressed concern over whether seattle city light and puget sound energy can handle the power necessary to run these hour high security facilities we are talking to about half a dozen customers that are requesting megawatts of power in a little area near southcenter mall said karl karzmar manager of revenue requirements for puget sound energy that is the equivalent of six oil refineries a relatively new phenomenon in the utility business the rise of the internet data center has some utility veterans scratching their heads puget sound energy last week asked the washington utilities and transportation commission to accept a tariff on the new data centers the tariff is designed to protect the company s existing residential and business customers from footing the bill for the new base stations necessary to support the projects those base stations could cost as much as million each karzmar said not to be left behind seattle city light plans to bring up the data center issue on thursday at the seattle city council meeting for the utilities that provide power to homes businesses and schools in the region this is a new and complex issue on one hand the data centers amazing appetite for power represent potentially lucrative business customers the facilities run hours a day seven days a week and therefore could become a constant revenue stream on the other hand they require so much energy that they could potentially flood the utilities with exorbitant capital expenditures who will pay for those expenditures and what it will mean for power rates in the area is still open to debate these facilities are what we call extremely dense loads said bob royer director of communications and public affairs at seattle city light the entire university of washington from stadium lights at the football game to the medical school averages megawatts per day we have data center projects in front of us that are asking for and megawatts with more than million square feet the intergate complex in tukwila is one of the biggest data centers sabey corp re purchased the million square foot intergate east facility last september from boeing space defense in less than months the developer has leased percent of the six building complex to seven different co location companies it is probably the largest data center park in the country boasts laurent poole chief operating officer at sabey exodus icg communications netstream communications pac west telecomm and zama networks all lease space in the office park after building exodus first tukwila facility in sabey has become an expert in the arena and now has facilities either under management or development in los angeles spokane and denver poole claims his firm is one of the top four builders of internet data centers in the country as more people access the internet and conduct bandwidth heavy tasks such as listening to online music poole said the need for co location space in seattle continues to escalate but it is not just seattle the need for data center space is growing at a rapid clip at many technology hubs throughout the country causing similar concerns among utilities in places such as texas and california exodus one of the largest providers of co location space plans to nearly double the amount of space it has by the end of the year while companies such as amazon com run their own server farms many high tech companies have decided to outsource the operations to companies such as exodus that may be better prepared for dealing with internet traffic management we have million square feet of space under construction and we plan to double our size in the next nine months yet there is more demand right now than data center space said steve porter an account executive at exodus in seattle the booming market for co location space has left some in the local utility industry perplexed it accelerates in a quantum way what you have to do to serve the growth said seattle city light s royer the utility industry is almost stunned by this in a way \n",
      "63\n",
      "the commercial support people that you and hunter want to make commercial managers \n",
      "64\n",
      "resumes of whom \n",
      "65\n",
      " john lavorato m mike grigsby d keith holst d frank ermis d steve south d janie tholt d scott neal p hunter shively p tom martin p john arnold p \n",
      "66\n",
      "mark here is a spreadsheet detailing our september socal trades i did not distinguish between buys vs sells phillip \n",
      "67\n",
      " on price caps pdf \n",
      "68\n",
      "richard compare your california production to the numbers in the california gas report it shows but again that might be just what the two utilities receive \n",
      "69\n",
      "cooper can you give access to the new west power site to jay reitmeyer he is an analyst in our group phillip\n",
      "70\n",
      " john lavorato m mike grigsby d keith holst d frank ermis d steve south d janie tholt d scott neal p hunter shively p tom martin p john arnold p \n",
      "71\n",
      "current notes user to ensure that you experience a successful migration from notes to outlook it is necessary to gather individual user information prior to your date o f migration please take a few minutes to completely fill out the followin g survey when you finish simply click on the reply button then hit se nd your survey will automatically be sent to the outlook migration m ailbox thank you outlook migration team \n",
      "72\n",
      "john lavorato m mike grigsby d keith holst d frank ermis d steve south d janie tholt d scott neal p hunter shively p tom martin p john arnold p\n",
      "73\n",
      "mark here is a spreadsheet detailing our september socal trades i did not distinguish between buys vs sells phillip \n",
      "74\n",
      "greg got your message good luck on the bike ride what were you doing to your apartment are you setting up a studio the kids are back in school otherwise just work is going on here keith\n",
      "75\n",
      "why are his requests coming to me \n",
      "76\n",
      "mark here is a spreadsheet detailing our september socal trades i did not distinguish between buys vs sells phillip\n",
      "77\n",
      "mark were you able to log in to enron online and find socal today i will follow up with a list of our physical deals done yesterday and today phillip\n",
      "78\n",
      "brenda can you send me your address in college station phillip\n",
      "79\n",
      " sorry report as of august \n",
      "80\n",
      "mark the following is a guest password that will allow you temporary view only access to enrononline please note the user id and password are case sensitive guest user id gna guest password yjku log in to www enrononline com and install shockwave using instructions below i have set up a composite page with western basis and cash prices to help you filter through the products the title of the composite page is mark s page if you have any problems logging in you can call me at or kathy moore enrononline helpdesk help the shockwave installer can be found within about enrononline on the home page after opening about enrononline using right scroll bar go to the bottom click on download shockwave and follow the directions after loading shockwave shut down and reopen browser i e microsoft internet explorer netscape i hope you will find this site useful sincerely phillip allen \n",
      "81\n",
      "mark attached is a spreadsheet that lists the end of day midmarkets for socal basis and socal san juan spreads i listed the days during bidweek that reflected financial trading for socal index and the actual gas daily prints before and after bidweek the following observations can be made july the basis market anticipated a socal san juan spread of vs actual of perceived index was vs actual of socal gas daily swaps are trading at a significant premium aug the basis market anticipated a socal san juan spread of vs actual of perceived index was vs actual of gas daily spreads were much wider before and after bidweek than the monthly postings socal gas daily swaps are trading at a significant premium enron online will allow you to monitor the value of financial swaps against the index as well as spreads to other locations please call with any questions phillip \n",
      "82\n",
      "alan you should have received updated numbers from keith holst call me if you did not receive them phillip\n",
      "83\n",
      "suzanne can you give me more details or email the plan prior to meeting what do i need to provide besides headcount otherwise any afternoon next week would be fine phillip\n",
      "84\n",
      "colleen please add mike grigsby to the distribution on another note do you have any idea how patti is holding up phillip\n",
      "85\n",
      "brad with regard to tori kuykendall i would like to promote her to commercial manager instead of converting her from a commercial support manager to an associate her duties since the beginning of the year have been those of a commercial manager i have no doubt that she will compare favorably to others in that category at year end martin cuilla on the central desk is in a similiar situation as tori hunter would like martin handled the same as tori let me know if there are any issues phillip\n",
      "86\n",
      "bruce can you stop by and set up my reuters phillip\n",
      "87\n",
      "lucy the rent roll spreadsheet is starting to look better see if you can add these modifications use a formula in column e add the value in column c to column d it should read c d then copy this formula to the rows below column h needs a formula subtract amount paid from amount owed e g column f is filled with the sign this is because the column width is too narrow use you mouse to click on the line beside the letter f hold the left mouse button down and drag the column wider after we get the rent part fixed lets bring the database columns up to this sheet and place them to the right in columns j and beyond phillip\n",
      "88\n",
      "lucy i got your email with the attachment let s work together today to get this done phillip\n",
      "89\n",
      "you have my approval\n",
      "90\n",
      "lucy we can discuss your email later how is progress on creating the spreadsheets you will probably need to close the file before you attach to an email it is i really want to make some progress on these two files phillip\n",
      "91\n",
      "lucy please open this excel file and input the rents and names due for this week then email the file back \n",
      "92\n",
      "open the utility spreadsheet and try to complete the analysis of whether it is better to be a small commercial or a medium commercial lp you will need to get the usage for that meter for the last months if we have one year of data we can tell which will be cheaper use the rates described in the spreadsheet this is a great chance for you to practice excel \n",
      "93\n",
      "alan steve has asked that you update the power point below so that it reflects all of the stupid regulatory legislative decisions since the beginning of the year ken wants to have this updated chart in his briefing book for next week s ken lay tour to ca he also wants a forward price curve for both gas and power in ca can we get these three documents by monday afternoon \n",
      "94\n",
      "mac thanks for the research report on eog here are my observations gas sales day x days year estimated gas prices mcf actual gas prices are around mcf higher and rising recalc of eps with more accurate gas prices mct x mcf shares outst additional eps x p e multiple a share that is just a back of the envelope valuation based on gas prices i think crude price are undervalued by the tune of share current price nat gas crude total can you take a look at these numbers and play devil s advocate to me this looks like the best stock to own also can you send me a report on calpine tosco and slb thank you phillip \n",
      "95\n",
      " phillip we have been working on different apartments today and having to listen to different people about what mary is saying should i be worried ants seem to be invading my apartment you got my other fax s wade is working on the bulletin board that i need up so that i can let tenants know about what is going on gave a notice about having to many people staying in that apt and that problem has been resolved also i have a tenant in that is complaining about using fowl language i sent a lease violation we will see how that goes call you tomorrow thanx lucy get your private free e mail from msn hotmail at \n",
      "96\n",
      " phillip the a c i bought today for cost pd by ck at wal mart also on ralph s appliance centerck frig stove for apt b ivoice amt stove frig del chrg tax total fax machine for ffice ck from steelman office produc ts thanxs lucy get your private free e mail from msn hotmail at \n",
      "97\n",
      " phillip today was one of those days because wade had to go pay his fine and i had to go take him that takes alot of time out of my schedule if you get a chance will you mention to him that he needs to try to fix his van so tht he can go get what ever he needs tomorrow gary is going to be here i have to go but iwill e mail you tomorrow lucy get your private free e mail from msn hotmail at \n",
      "98\n",
      "i checked into exercising options with smith barney but enron has some kind of exclusive with paine weber i am starting to exercise now but i am going to use the proceeds to buy another apartment complex what do you think about selling jdsu and buying sdli also can you look at eog as a play on rising oil and gas prices thanks phillip\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(emails.iloc[i,9])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ураа! Теперь нас есть финальные тексты сообщений без лишних символов и данных!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для следующего задания вам нужно будет токенизировать текст. Для этого просто разбейте его по словам. Очевидно, итоговый результат будет лучше, если ваша система также будет предлагать уместную пунктуацию. Но если вы считаете, что результат получается лучше без нее, то можете удалить все небуквенные символы на этапе токенизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "emails['message_tokenized'] = emails['message_preprocessed'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнение слова\n",
    "\n",
    "Описанная система будет состоять из двух частей: дополнение слова до целого и генерация продолжения текста (или вариантов продолжений). Начнем с первой части.\n",
    "\n",
    "В этой части вам предстоит реализовать метод дополнения слова до целого по его началу (префиксу). Для этого сперва необходимо научиться находить все слова, имеющие определенный префикс. Мы будем вызывать функцию поиска подходящих слов после каждой напечатанной пользователем буквы. Поэтому нам очень важно, чтобы поиск работал как можно быстрее. Простой перебор всех слов занимает $O(|V| \\cdot n)$ времени, где $|V|$ – размер словаря, а $n$ – длина префикса. Мы же напишем [префиксное дерево](https://ru.wikipedia.org/wiki/Префиксное_дерево), которое позволяет искать слова за $O(n + m)$, где $m$ – число подходящих слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2 (1 балл).__ Допишите префиксное дерево для поиска слов по префиксу. Ваше дерево должно работать за $O(n + m)$ операции, в противном случае вы не получите баллов за это задание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class PrefixTreeNode:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # словарь с буквами, которые могут идти после данной вершины\n",
    "        self.children: dict[str, PrefixTreeNode] = {}\n",
    "        self.is_end_of_word = False  # является ли текущая вершина концом слова\n",
    "\n",
    "class PrefixTree:\n",
    "    def __init__(self, vocabulary: List[str]):\n",
    "        \"\"\"\n",
    "        vocabulary: список всех уникальных токенов в корпусе\n",
    "        \"\"\"\n",
    "        self.root = PrefixTreeNode()\n",
    "        \n",
    "        # заполняем префиксное дерево\n",
    "        \n",
    "        for word in vocabulary:\n",
    "            self.insert_word(word)\n",
    "\n",
    "    def insert_word(self, word: str):\n",
    "        \"\"\"\n",
    "        Вставляет слово в префиксное дерево\n",
    "        \"\"\"\n",
    "        node = self.root\n",
    "        \n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                node.children[char] = PrefixTreeNode()\n",
    "                \n",
    "            node = node.children[char]\n",
    "            \n",
    "        node.is_end_of_word = True\n",
    "\n",
    "    def collect_words(self, node: PrefixTreeNode, prefix: str, results: List[str]):\n",
    "        \"\"\"\n",
    "        Рекурсивно собирает все слова, начинающиеся с данного префикса\n",
    "        \"\"\"\n",
    "        if node.is_end_of_word:\n",
    "            results.append(prefix)\n",
    "        for char, child_node in node.children.items():\n",
    "            self.collect_words(child_node, prefix + char, results)\n",
    "\n",
    "    def search_prefix(self, prefix: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Возвращает все слова, начинающиеся на prefix\n",
    "        prefix: str – префикс слова\n",
    "        \"\"\"\n",
    "        node = self.root\n",
    "        \n",
    "        # проходим по дереву по символам префикса\n",
    "        for char in prefix:\n",
    "            \n",
    "            if char not in node.children:\n",
    "                return []  # если префикс не найден\n",
    "                \n",
    "            node = node.children[char]\n",
    "        \n",
    "        # Если префикс найден, собираем все слова, начинающиеся с этого префикса\n",
    "        \n",
    "        results = []\n",
    "        self.collect_words(node, prefix, results)\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = ['aa', 'aaa', 'abb', 'bba', 'bbb', 'bcd']\n",
    "prefix_tree = PrefixTree(vocabulary)\n",
    "\n",
    "assert set(prefix_tree.search_prefix('a')) == set(['aa', 'aaa', 'abb'])\n",
    "assert set(prefix_tree.search_prefix('bb')) == set(['bba', 'bbb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда у нас есть способ быстро находить все слова с определенным префиксом, нам нужно их упорядочить по вероятности, чтобы выбирать лучшее. Будем оценивать вероятность слова по частоте его встречаемости в корпусе.\n",
    "\n",
    "__Задание 3 (1 балл).__ Допишите класс `WordCompletor`, который формирует словарь и префиксное дерево, а так же умеет находить все возможные продолжения слова вместе с их вероятностями. В этом классе вы можете при необходимости дополнительно отфильтровать слова, например, удалив все самые редкие. Постарайтесь максимально оптимизировать ваш код."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCompletor:\n",
    "    \n",
    "    def __init__(self, corpus: List[str]):\n",
    "        \"\"\"\n",
    "        corpus: list – корпус текстов\n",
    "        \"\"\"\n",
    "        # подсчитываем частоту каждого слова в корпусе\n",
    "\n",
    "        self.word_frequency = Counter(list(itertools.chain.from_iterable(corpus))) \n",
    "\n",
    "        vocabulary = list(self.word_frequency.keys())\n",
    "\n",
    "        self.prefix_tree = PrefixTree(vocabulary)\n",
    "    \n",
    "\n",
    "    def get_words_and_probs(self, prefix: str) -> Tuple[List[str], List[float]]:\n",
    "        \"\"\"\n",
    "        Возвращает список слов, начинающихся на prefix, с их вероятностями\n",
    "        (нормировать ничего не нужно)\n",
    "        \"\"\"\n",
    "\n",
    "        words = self.prefix_tree.search_prefix(prefix)\n",
    "        \n",
    "        total = sum(self.word_frequency.values())\n",
    "        \n",
    "        probs = [self.word_frequency[word]/total if total > 0 else 0 for word in words]\n",
    "\n",
    "        return words, probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_corpus = [\n",
    "    [\"aa\", \"ab\"],\n",
    "    [\"aaa\", \"abab\"],\n",
    "    [\"abb\", \"aa\", \"ab\", \"bba\", \"bbb\", \"bcd\"],\n",
    "]\n",
    "\n",
    "word_completor = WordCompletor(dummy_corpus)\n",
    "words, probs = word_completor.get_words_and_probs('a')\n",
    "words_probs = list(zip(words, probs))\n",
    "assert set(words_probs) == {('aa', 0.2), ('ab', 0.2), ('aaa', 0.1), ('abab', 0.1), ('abb', 0.1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание следующих слов\n",
    "\n",
    "Теперь, когда мы умеем дописывать слово за пользователем, мы можем пойти дальше и предожить ему несколько следующих слов с учетом дописанного. Для этого мы воспользуемся n-граммами и будем советовать n следующих слов. Но сперва нужно получить n-граммную модель.\n",
    "\n",
    "Напомним, что вероятность последовательности для такой модели записывается по формуле\n",
    "$$\n",
    "P(w_1, \\dots, w_T) = \\prod_{i=1}^T P(w_i \\mid w_{i-1}, \\dots, w_{i-n}).\n",
    "$$\n",
    "\n",
    "Тогда, нам нужно оценить $P(w_i \\mid w_{i-1}, \\dots, w_{i-n})$ по частоте встречаемости n-граммы.   \n",
    "\n",
    "__Задание 4 (1 балл).__ Напишите класс для n-граммной модели. Понятное дело, никакого сглаживания добавлять не надо, мы же не хотим, чтобы модель советовала случайные слова (хоть и очень редко)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModel:\n",
    "    def __init__(self, corpus: List[str], n: int):\n",
    "\n",
    "        \"\"\"\n",
    "        corpus: список предложений (каждое предложение представлено как строка слов)\n",
    "        n: размер n-грамм\n",
    "        \"\"\"\n",
    "\n",
    "        self.n = n\n",
    "        self.ngram_next_counts = defaultdict(Counter)\n",
    "        self.ngram_counts = Counter()\n",
    "        \n",
    "        # строим n-граммную модель\n",
    "        # для каждого предложения (текста) из корпуса\n",
    "        # генерируем всевозможные Н-граммы, добавляя их в словарь\n",
    "        # и подсчитывая их частоту\n",
    "        \n",
    "        for sent in corpus:\n",
    "            ngrams, ngrams_w_next = self.make_ngrams(sent, n)\n",
    "            for ngram, ngram_next in zip(ngrams, ngrams_w_next):\n",
    "                self.ngram_next_counts[ngram][ngram_next[-1]] += 1\n",
    "                self.ngram_counts[ngram] += 1\n",
    "\n",
    "\n",
    "    def make_ngrams(self, sentence: str, n: int):\n",
    "\n",
    "        \"\"\"\n",
    "        Генерирует n-граммы из предложения.\n",
    "        Возвращает список n-грамм и список предшествующих (n-1) элементов.\n",
    "        \"\"\"\n",
    "        # для того, чтобы Н-граммы только с первым словом могли генерироваться, заполняем  n-1 позиций\n",
    "        # предложения начальными токенами\n",
    "        # и я добавила конечный токен на всякий случай (чтобы мы могли отслеживать, какое слово встречается в конце чаще всего)\n",
    "\n",
    "        sentence = (n-1) * ['<PAD>'] + sentence + ['.']\n",
    "        ngrams = []\n",
    "        ngrams_w_next = []\n",
    "\n",
    "        for i in range(n - 1, len(sentence)-1):\n",
    "            \n",
    "            preceding = sentence[i - n + 1:i+1]  # предыдущие (n-1) слова и текущее n слово (то есть n-грамма)\n",
    "            word = sentence[i+1]  # следующее слово (его сохраняем, чтобы в явном виде отслеживать частотность после n-граммы)\n",
    "            \n",
    "            ngrams_w_next.append(tuple([*preceding, word])) # тут n-граммы со следующим словом\n",
    "            ngrams.append(tuple(preceding)) # тут просто n-граммы (ключи следующих слов)\n",
    "        \n",
    "        return ngrams, ngrams_w_next\n",
    "\n",
    "    def get_next_words_and_probs(self, prefix: List[str]) -> Tuple[List[str], List[float]]:\n",
    "        \"\"\"\n",
    "        Возвращает список слов, которые могут идти после prefix,\n",
    "        а так же список вероятностей этих слов.\n",
    "        prefix: список предыдущих (n-1) слов.\n",
    "        \"\"\"\n",
    "        # превращаем префикс в tuple (предыдущие n-1 слов)\n",
    "        if len(prefix) <= self.n-1:\n",
    "            prefix_tuple = tuple(prefix) # если префикс это не n-грамма (не хватает слов), то он полностью участвует в предсказании\n",
    "        else:\n",
    "            prefix_tuple = tuple(prefix[-(self.n):]) # если в префиксе слов не меньше, чем n, то от него берем только последнюю n-грамму\n",
    "\n",
    "        if prefix_tuple not in self.ngram_counts:\n",
    "            return [], []  # если префикс не найден\n",
    "        \n",
    "        # получаем счетчики следующих слов\n",
    "        next_word_counts = self.ngram_next_counts[prefix_tuple]\n",
    "        total_count = self.ngram_counts[prefix_tuple]\n",
    "        \n",
    "        next_words = [word for word in next_word_counts.keys()]\n",
    "        probs = [count/total_count for count in next_word_counts.values()]\n",
    "        \n",
    "        return next_words, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_corpus = [\n",
    "    ['aa', 'aa', 'aa', 'aa', 'ab'],\n",
    "    ['aaa', 'abab'],\n",
    "    ['abb', 'aa', 'ab', 'bba', 'bbb', 'bcd']\n",
    "]\n",
    "\n",
    "n_gram_model = NGramLanguageModel(corpus=dummy_corpus, n=2)\n",
    "\n",
    "next_words, probs = n_gram_model.get_next_words_and_probs(['aa', 'aa'])\n",
    "words_probs = list(zip(next_words, probs))\n",
    "\n",
    "assert set(words_probs) == {('aa', 2/3), ('ab', 1/3)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, мы теперь можем объединить два метода в автоматический дописыватель текстов: первый будет дополнять слово, а второй – предлагать продолжения. Хочется, чтобы предлагался список возможных продолжений, из который пользователь сможет выбрать наиболее подходящее. Самое сложное тут – аккуратно выбирать, что показывать, а что нет.   \n",
    "\n",
    "__Задание 5 (1 балл).__ В качестве первого подхода к снаряду реализуйте метод, возвращающий всегда самое вероятное продолжение жадным способом. Если вы справитесь, то сможете можете добавить опцию поддержки нескольких вариантов продолжений, что сделает метод гораздо лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSuggestion:\n",
    "    def __init__(self, word_completor, n_gram_model):\n",
    "        self.word_completor = word_completor\n",
    "        self.n_gram_model = n_gram_model\n",
    "\n",
    "    def suggest_text(self, text: Union[str, list], n_words=3, n_texts=1) -> list[list[str]]:\n",
    "        \"\"\"\n",
    "        Возвращает возможные варианты продолжения текста (по умолчанию только один)\n",
    "        \n",
    "        text: строка или список слов – написанный пользователем текст\n",
    "        n_words: число слов, которые дописывает n-граммная модель\n",
    "        n_texts: число возвращаемых продолжений (пока что только одно)\n",
    "        \n",
    "        return: list[list[srt]] – список из n_texts списков слов, по 1 + n_words слов в каждом\n",
    "        Первое слово – это то, которое WordCompletor дополнил до целого.\n",
    "        \"\"\"\n",
    "        suggestions = []\n",
    "        \n",
    "        # дописывание слова\n",
    "        \n",
    "        string_options, string_probs = self.word_completor.get_words_and_probs(text[-1])\n",
    "        \n",
    "\n",
    "        # отсортировала по вероятностям\n",
    "\n",
    "        string_zip = sorted(zip(string_probs, string_options), reverse = True)\n",
    "\n",
    "        if len(string_zip) > 0:\n",
    "\n",
    "            best_string = string_zip[0][1] # если мы вообще что-то предсказали как продолжение, берем самое вероятное слово\n",
    "            \n",
    "        else:\n",
    "            best_string = text[-1] # если не находится продолжений для слова, просто оставляем его как было\n",
    "\n",
    "        text[-1] = best_string # наш жадный поиск начинается с того, что мы берем наше дописанное слово как последнее для предсказания\n",
    "        \n",
    "        for i in range(n_words):\n",
    "\n",
    "            \n",
    "            sentence_options, sentence_probs = self.n_gram_model.get_next_words_and_probs(text)\n",
    "            sentence_zip = sorted(zip(sentence_probs, sentence_options), reverse = True)\n",
    "\n",
    "            if len(sentence_zip) > 0:\n",
    "                best_sentence = \"\"\n",
    "                best_sentence = sentence_zip[0][1] # если что-то находим - берем самое вероятное продолжение\n",
    "\n",
    "            else:\n",
    "                break\n",
    "            text.append(best_sentence) # добавляем самое вероятное продолжение, чтобы от него жадным способом искать следующие\n",
    "\n",
    "        suggestions.append(list(text[-(n_words+1):])) # из добавленных слов в текст забираем только предсказанные\n",
    "\n",
    "        return suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_corpus = [\n",
    "    ['aa', 'aa', 'aa', 'aa', 'ab'],\n",
    "    ['aaa', 'abab'],\n",
    "    ['abb', 'aa', 'ab', 'bba', 'bbb', 'bcd']\n",
    "]\n",
    "\n",
    "word_completor = WordCompletor(dummy_corpus)\n",
    "n_gram_model = NGramLanguageModel(corpus=dummy_corpus, n=2)\n",
    "text_suggestion = TextSuggestion(word_completor, n_gram_model)\n",
    "\n",
    "assert text_suggestion.suggest_text(['aa', 'aa'], n_words=3, n_texts=1) == [['aa', 'aa', 'aa', 'aa']]\n",
    "assert text_suggestion.suggest_text(['abb', 'aa', 'ab'], n_words=2, n_texts=1) == [['ab', 'bba', 'bbb']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_corpus = emails.iloc[:1000,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              [here, is, our, forecast]\n",
       "1      [traveling, to, have, a, business, meeting, ta...\n",
       "2                        [test, successful, way, to, go]\n",
       "3      [randy, can, you, send, me, a, schedule, of, t...\n",
       "4                      [let, s, shoot, for, tuesday, at]\n",
       "                             ...                        \n",
       "995    [jacques, still, trying, to, close, the, loop,...\n",
       "996    [larrry, i, realize, you, are, disappointed, a...\n",
       "997    [phillip, how, are, you, and, how, is, everyon...\n",
       "998    [jacques, i, think, we, reached, an, agreement...\n",
       "999    [let, s, talk, to, matt, about, the, forecast,...\n",
       "Name: message_tokenized, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_model1 = NGramLanguageModel(corpus=my_corpus, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_completor1 = WordCompletor(my_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_suggestion1 = TextSuggestion(word_completor1, n_gram_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['is', 'a', 'spreadsheet', 'that']]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_suggestion1.suggest_text(['here', 'is'], n_words=3, n_texts=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчет в конце ноутбука, после второй части"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настало время довести вашу систему до ума. В этой части вы можете модифицировать все классы по своему усмотрению и добавлять любые эвристики. Если нужно, то дополнительно обрабатывать текст и вообще делать все, что считаете нужным, __кроме использования дополнительных данных__. Главное – вы должны обернуть вашу систему в пользовательский интерфейс с помощью [reflex](https://github.com/reflex-dev/reflex). В нем можно реализовать почти любой функционал по вашему желанию.\n",
    "\n",
    "Мы настоятельно рекомендуем вам оформить код в проект, а не писать в ноутбуке. Но если вам очень хочется писать тут, то хотя бы не меняйте код в предыдущих заданиях, чтобы его можно было нормально оценивать.\n",
    "\n",
    "При сдаче решения прикрепите весь ваш __код__, __отчет__ по второй части и __видео__ с демонстрацией работы вашей системы. Удачи!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие я вижу способы улучшения того, что у нас есть сейчас?\n",
    "\n",
    "1. Наличие редких слов и н-грамм замедляет работу нашей программы, занимает дополнительное место, при этом редкие слова практически никогда не будут использоваться, так как наш выбор основан на частотности н-грам. То есть, их нужно убрать, по возможности\n",
    "\n",
    "2. Промпт должен обрабатываться должным образом (мы не знаем, что пользователь захочет ввести в строку ввода, может, это будут цифры или знаки пунктуации)\n",
    "\n",
    "3. Оптимальный подбор n в n-граммах (посчитать TF-IDF для всех n-грамм ?)\n",
    "\n",
    "4. Предсказывание нескольких вариантов продолжения\n",
    "\n",
    "5. Еще можно как-то отбирать наиболее информативные n-граммы, пытаться оставлять только те, что сильно улучшают качество и повышают вероятность комбинации слов, выделять отдельные формулы подсчета вероятности, чтобы на их основе отбирать н-граммы, а не просто жадным способом. Но это, как мне кажется, уже более трудозатратная задача, так что оставим ее релаизацию на потом\n",
    "\n",
    "Попробуем реализовать что-то из этого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в новом классе я отбрасываю все н-граммы, которые встречаются только 1 раз\n",
    "\n",
    "class NGramLanguageModel_new:\n",
    "    def __init__(self, corpus: List[str], n: int):\n",
    "\n",
    "        \"\"\"\n",
    "        corpus: список предложений (каждое предложение представлено как строка слов)\n",
    "        n: размер n-грамм\n",
    "        \"\"\"\n",
    "\n",
    "        self.n = n\n",
    "        self.ngram_next_counts = defaultdict(Counter)\n",
    "        self.ngram_counts = Counter()\n",
    "        \n",
    "        # строим n-граммную модель\n",
    "        # для каждого предложения (текста) из корпуса\n",
    "        # генерируем всевозможные Н-граммы, добавляя их в словарь\n",
    "        # и подсчитывая их частоту\n",
    "        \n",
    "        for sent in corpus:\n",
    "            ngrams, ngrams_w_next = self.make_ngrams(sent, n)\n",
    "            for ngram, ngram_next in zip(ngrams, ngrams_w_next):\n",
    "                self.ngram_next_counts[ngram][ngram_next[-1]] += 1\n",
    "                self.ngram_counts[ngram] += 1\n",
    "\n",
    "        # убираем редкие n-граммы\n",
    "        self.ngram_counts = {x: count for x, count in self.ngram_counts.items() if count > 1}\n",
    "\n",
    "\n",
    "    def make_ngrams(self, sentence: str, n: int):\n",
    "\n",
    "        \"\"\"\n",
    "        Генерирует n-граммы из предложения.\n",
    "        Возвращает список n-грамм и список предшествующих (n-1) элементов.\n",
    "        \"\"\"\n",
    "        # для того, чтобы Н-граммы только с первым словом могли генерироваться, заполняем  n-1 позиций\n",
    "        # предложения начальными токенами\n",
    "        # и я добавила конечный токен на всякий случай (чтобы мы могли отслеживать, какое слово встречается в конце чаще всего)\n",
    "\n",
    "        sentence = (n-1) * ['<PAD>'] + sentence + ['.']\n",
    "        ngrams = []\n",
    "        ngrams_w_next = []\n",
    "\n",
    "        for i in range(n - 1, len(sentence)-1):\n",
    "            \n",
    "            preceding = sentence[i - n + 1:i+1]  # предыдущие (n-1) слова и текущее n слово (то есть n-грамма)\n",
    "            word = sentence[i+1]  # следующее слово (его сохраняем, чтобы в явном виде отслеживать частотность после n-граммы)\n",
    "            \n",
    "            ngrams_w_next.append(tuple([*preceding, word])) # тут n-граммы со следующим словом\n",
    "            ngrams.append(tuple(preceding)) # тут просто n-граммы (ключи следующих слов)\n",
    "        \n",
    "        return ngrams, ngrams_w_next\n",
    "\n",
    "    def get_next_words_and_probs(self, prefix: List[str]) -> Tuple[List[str], List[float]]:\n",
    "        \"\"\"\n",
    "        Возвращает список слов, которые могут идти после prefix,\n",
    "        а так же список вероятностей этих слов.\n",
    "        prefix: список предыдущих (n-1) слов.\n",
    "        \"\"\"\n",
    "        # превращаем префикс в tuple (предыдущие n-1 слов)\n",
    "        if len(prefix) <= self.n-1:\n",
    "            prefix_tuple = tuple(prefix) # если префикс это не n-грамма (не хватает слов), то он полностью участвует в предсказании\n",
    "        else:\n",
    "            prefix_tuple = tuple(prefix[-(self.n):]) # если в префиксе слов не меньше, чем n, то от него берем только последнюю n-грамму\n",
    "\n",
    "        if prefix_tuple not in self.ngram_counts:\n",
    "            return [], []  # если префикс не найден\n",
    "        \n",
    "        # получаем счетчики следующих слов\n",
    "        next_word_counts = self.ngram_next_counts[prefix_tuple]\n",
    "        total_count = self.ngram_counts[prefix_tuple]\n",
    "        \n",
    "        next_words = [word for word in next_word_counts.keys()]\n",
    "        probs = [count/total_count for count in next_word_counts.values()]\n",
    "        \n",
    "        return next_words, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# в новом классе подсказчика я реализую предсказание второго лучшего продолжения текста\n",
    "# (на первой итерации выбираем второе по вероятности слово)\n",
    "\n",
    "class TextSuggestion_new:\n",
    "    def __init__(self, word_completor, n_gram_model):\n",
    "        self.word_completor = word_completor\n",
    "        self.n_gram_model = n_gram_model\n",
    "\n",
    "    def suggest_text(self, text: Union[str, list], n_words=3, n_texts=1) -> list[list[str]]:\n",
    "        \"\"\"\n",
    "        Возвращает возможные варианты продолжения текста (по умолчанию только один)\n",
    "        \n",
    "        text: строка или список слов – написанный пользователем текст\n",
    "        n_words: число слов, которые дописывает n-граммная модель\n",
    "        n_texts: число возвращаемых продолжений (пока что только одно)\n",
    "        \n",
    "        return: list[list[srt]] – список из n_texts списков слов, по 1 + n_words слов в каждом\n",
    "        Первое слово – это то, которое WordCompletor дополнил до целого.\n",
    "        \"\"\"\n",
    "        # prompt preprocessing!\n",
    "        \n",
    "        text = [t.lower() for t in text]\n",
    "        text = [re.sub('\\d+', '', t) for t in text]\n",
    "        text = [t.replace('\\n', ' ') for t in text]\n",
    "        text = [re.sub(r'[^a-zA-Z\\s]', ' ', t) for t in text]\n",
    "        \n",
    "        suggestions = []\n",
    "        \n",
    "        # дописывание слова\n",
    "        \n",
    "        string_options, string_probs = self.word_completor.get_words_and_probs(text[-1])\n",
    "        \n",
    "\n",
    "        # отсортировала по вероятностям\n",
    "\n",
    "        string_zip = sorted(zip(string_probs, string_options), reverse = True)\n",
    "\n",
    "        if len(string_zip) > 0:\n",
    "\n",
    "            best_string = string_zip[0][1] # если мы вообще что-то предсказали как продолжение, берем самое вероятное слово\n",
    "            \n",
    "        else:\n",
    "            best_string = text[-1] # если не находится продолжений для слова, просто оставляем его как было\n",
    "\n",
    "        text[-1] = best_string # наш жадный поиск начинается с того, что мы берем наше дописанное слово как последнее для предсказания\n",
    "        text_2 = copy.deepcopy(text)\n",
    "        for i in range(n_words):\n",
    "\n",
    "            \n",
    "            sentence_options, sentence_probs = self.n_gram_model.get_next_words_and_probs(text)\n",
    "            sentence_zip = sorted(zip(sentence_probs, sentence_options), reverse = True)\n",
    "\n",
    "            if len(sentence_zip) > 0:\n",
    "                best_sentence = \"\"\n",
    "                best_sentence = sentence_zip[0][1] # если что-то находим - берем самое вероятное продолжение\n",
    "\n",
    "            else:\n",
    "                break\n",
    "            text.append(best_sentence) # добавляем самое вероятное продолжение, чтобы от него жадным способом искать следующие\n",
    "\n",
    "        suggestions.append(list(text[-(n_words+1):])) # из добавленных слов в текст забираем только предсказанные\n",
    "\n",
    "        # добавляем второе предсказание: на первой итерации выбираем второй наиболее вероятный вариант,\n",
    "        # а на следующих - первые, все так же\n",
    "        \n",
    "        for i in range(n_words):\n",
    "\n",
    "            \n",
    "            sentence_options, sentence_probs = self.n_gram_model.get_next_words_and_probs(text_2)\n",
    "            sentence_zip = sorted(zip(sentence_probs, sentence_options), reverse = True)\n",
    "\n",
    "            if len(sentence_zip) > 0 and i == 0:\n",
    "                best_sentence = \"\"\n",
    "                best_sentence = sentence_zip[1][1] \n",
    "            elif len(sentence_zip) > 0 and i > 0:\n",
    "                best_sentence = \"\"\n",
    "                best_sentence = sentence_zip[0][1]\n",
    "            else:\n",
    "                break\n",
    "            text_2.append(best_sentence) \n",
    "\n",
    "        suggestions.append(list(text_2[-(n_words+1):])) \n",
    "\n",
    "        # аналогичное можно проделать с большим количеством предложений и повторить для подсказки слов\n",
    "\n",
    "        return suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_corpus = emails.iloc[:1000,10]\n",
    "my_corpus\n",
    "n_gram_model1 = NGramLanguageModel_new(corpus=my_corpus, n=2)\n",
    "word_completor1 = WordCompletor(my_corpus)\n",
    "text_suggestion1 = TextSuggestion_new(word_completor1, n_gram_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['want', 'to', 'be', 'a'], ['want', 'your', 'print', 'out']]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_suggestion1.suggest_text(['i', 'want'], n_words=3, n_texts=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полный код проекта, через который я запускала приложение из видео:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reflex as rx\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Union, List, Tuple\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "\n",
    "emails = pd.read_csv('emails.csv')\n",
    "my_corpus = emails.iloc[:50,:]\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/alina/NGramModel/')\n",
    "from rxconfig import config\n",
    "\n",
    "class PrefixTreeNode:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.children = {}\n",
    "        self.is_end_of_word = False \n",
    "\n",
    "class PrefixTree:\n",
    "    def __init__(self, vocabulary):\n",
    "\n",
    "        self.root = PrefixTreeNode()\n",
    "        for word in vocabulary:\n",
    "            self._insert(word)\n",
    "\n",
    "    def _insert(self, word: str):\n",
    "\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                node.children[char] = PrefixTreeNode()\n",
    "            node = node.children[char]\n",
    "        node.is_end_of_word = True\n",
    "\n",
    "    def _collect_words(self, node, prefix, results):\n",
    "\n",
    "        if node.is_end_of_word:\n",
    "            results.append(prefix)\n",
    "        for char, child_node in node.children.items():\n",
    "            self._collect_words(child_node, prefix + char, results)\n",
    "\n",
    "    def search_prefix(self, prefix):\n",
    "\n",
    "        node = self.root\n",
    "\n",
    "        for char in prefix:\n",
    "            if char not in node.children:\n",
    "                return [] \n",
    "            node = node.children[char]\n",
    "        \n",
    "   \n",
    "        results = []\n",
    "        self._collect_words(node, prefix, results)\n",
    "        return results\n",
    "\n",
    "class WordCompletor:\n",
    "    def __init__(self, corpus):\n",
    "\n",
    "        self.word_frequency = Counter(list(itertools.chain.from_iterable(corpus))) \n",
    "\n",
    "        vocabulary = list(self.word_frequency.keys())\n",
    "    \n",
    "        self.prefix_tree = PrefixTree(vocabulary)\n",
    "\n",
    "    def get_words_and_probs(self, prefix: str):\n",
    "\n",
    "\n",
    "        words = self.prefix_tree.search_prefix(prefix)\n",
    "        \n",
    "        total = sum(self.word_frequency.values())\n",
    "        \n",
    "        probs = [self.word_frequency[word]/total if total > 0 else 0 for word in words]\n",
    "\n",
    "        return words, probs\n",
    "    \n",
    "\n",
    "class NGramLanguageModel:\n",
    "    def __init__(self, corpus, n):\n",
    "\n",
    "        self.n = n\n",
    "        self.ngram_next_counts = defaultdict(Counter)\n",
    "        self.ngram_counts = Counter()\n",
    "        \n",
    "        for sent in corpus:\n",
    "            ngrams, ngrams_w_next = self.make_ngrams(sent, n)\n",
    "            for ngram, ngram_next in zip(ngrams, ngrams_w_next):\n",
    "                self.ngram_next_counts[ngram][ngram_next[-1]] += 1\n",
    "                self.ngram_counts[ngram] += 1\n",
    "\n",
    "\n",
    "    def make_ngrams(self, sentence, n):\n",
    "\n",
    "        sentence = (n-1) * ['<PAD>'] + sentence + ['.']\n",
    "        ngrams = []\n",
    "        ngrams_w_next = []\n",
    "\n",
    "        for i in range(n - 1, len(sentence)-1):\n",
    "            preceding = sentence[i - n + 1:i+1] \n",
    "            word = sentence[i+1]\n",
    "            ngrams_w_next.append(tuple([*preceding, word]))\n",
    "            ngrams.append(tuple(preceding))\n",
    "        \n",
    "        return ngrams, ngrams_w_next\n",
    "    \n",
    "    def get_next_words_and_probs(self, prefix):\n",
    "\n",
    "        if len(prefix) <= self.n-1:\n",
    "            prefix_tuple = tuple(prefix)\n",
    "        else:\n",
    "            prefix_tuple = tuple(prefix[-(self.n):])\n",
    "\n",
    "        if prefix_tuple not in self.ngram_counts:\n",
    "            return [], []\n",
    "        \n",
    "        next_word_counts = self.ngram_next_counts[prefix_tuple]\n",
    "        total_count = self.ngram_counts[prefix_tuple]\n",
    "        \n",
    "        next_words = [word for word in next_word_counts.keys()]\n",
    "        probs = [count/total_count for count in next_word_counts.values()]\n",
    "        \n",
    "        return next_words, probs\n",
    "\n",
    "class TextSuggestion:\n",
    "    def __init__(self, word_completor, n_gram_model):\n",
    "        self.word_completor = word_completor\n",
    "        self.n_gram_model = n_gram_model\n",
    "\n",
    "    def suggest_text(self, text, n_words=3, n_texts=1):\n",
    "\n",
    "        suggestions = []\n",
    "\n",
    "    \n",
    "        string_options, string_probs = self.word_completor.get_words_and_probs(text[-1])\n",
    "\n",
    "\n",
    "        string_zip = sorted(zip(string_probs, string_options), reverse = True)\n",
    "        \n",
    "        if len(string_zip) > 0:\n",
    "\n",
    "            best_string = string_zip[0][1]\n",
    "        else:\n",
    "            best_string = text[-1]\n",
    "\n",
    "        text[-1] = best_string\n",
    "\n",
    "        for i in range(n_words):\n",
    "            \n",
    "            sentence_options, sentence_probs = self.n_gram_model.get_next_words_and_probs(text)\n",
    "            sentence_zip = sorted(zip(sentence_probs, sentence_options), reverse = True)\n",
    "\n",
    "            if len(sentence_zip) > 0:\n",
    "                best_sentence = ''\n",
    "                best_sentence = sentence_zip[0][1]\n",
    "\n",
    "            else:\n",
    "                break\n",
    "            text.append(best_sentence)\n",
    "\n",
    "        suggestions.append(list(text[-(n_words+1):]))\n",
    "\n",
    "        return suggestions\n",
    "\n",
    "\n",
    "my_corpus['message_wo_metadata'] = my_corpus['message'].apply(lambda x: x.split('\\n\\n', 1)[1])\n",
    "\n",
    "\n",
    "\n",
    "def split_forward(msg):\n",
    "    \n",
    "    if 'Subject:' in msg:\n",
    "        return msg.rsplit('Subject:', 1)[-1].split('\\n\\n', 1)[-1]\n",
    "        \n",
    "    else:\n",
    "        return msg\n",
    "       \n",
    "my_corpus['message_wo_forward'] = my_corpus['message_wo_metadata'].apply(lambda x: split_forward(x))\n",
    "my_corpus['message_wo_meetings'] = my_corpus['message_wo_forward'].apply(lambda x: x.split('----------------------', 1)[0])\n",
    "my_corpus['message_wo_subscription_metadata'] = my_corpus['message_wo_meetings'].apply(lambda x: split_forward(x))\n",
    "\n",
    "\n",
    "my_corpus['message_wo_emails'] = my_corpus['message_wo_subscription_metadata'].apply(lambda x: re.sub(r'\\S*@\\S*\\s?', '', x))\n",
    "my_corpus['message_wo_urls'] = my_corpus['message_wo_emails'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "my_corpus['message_wo_files'] = my_corpus['message_wo_urls'].apply(lambda x: re.sub(r'-\\s\\S*.\\S*', '', x))\n",
    "\n",
    "def preprocess(x):\n",
    "\n",
    "    x_lowercase = x.lower()\n",
    "    x_no_digits = re.sub('\\d+', '', x_lowercase)\n",
    "    x_no_nextstring = x_no_digits.replace('\\n', ' ')\n",
    "    x_no_punctuation = re.sub(r'[^a-zA-Z\\s]', ' ', x_no_nextstring)\n",
    "    x_final = re.sub(' +', ' ', x_no_punctuation)\n",
    "\n",
    "    return x_final\n",
    "\n",
    "my_corpus['message_preprocessed'] = my_corpus['message_wo_files'].apply(lambda x: preprocess(x))\n",
    "my_corpus['message_tokenized'] = my_corpus['message_preprocessed'].apply(lambda x: x.split())\n",
    "\n",
    "word_completor = WordCompletor(my_corpus.iloc[:,10])\n",
    "n_gram_model = NGramLanguageModel(corpus=my_corpus.iloc[:,10], n=2)\n",
    "text_suggestion = TextSuggestion(word_completor, n_gram_model)\n",
    "\n",
    "\n",
    "class State(rx.State):\n",
    "\n",
    "    prompt = \"\"\n",
    "    suggested_text = \"\"\n",
    "    suggested_text_2 = \"\"\n",
    "    processing = False\n",
    "    complete = False\n",
    "\n",
    "    def get_suggestion(self):\n",
    "        if self.prompt == \"\":\n",
    "            return rx.window_alert(\"Please, enter the prompt!\")\n",
    "        self.processing, self.complete = True, False\n",
    "        yield\n",
    "        response = text_suggestion.suggest_text(list(self.prompt.split()), n_words=3, n_texts=1)\n",
    "        self.suggested_text = ' '.join(response[0])\n",
    "        self.processing, self.complete = False, True\n",
    "\n",
    "\n",
    "def index():\n",
    "    return rx.center(\n",
    "        rx.vstack(\n",
    "            rx.heading(\"Text suggestion online!\", size = \"8\",),\n",
    "            rx.heading(\n",
    "            \"Made by Grushina Daria, HSE-NES Joint Programme\",\n",
    "            size=\"5\",),\n",
    "            rx.input(\n",
    "                placeholder=\"Enter a prompt... \",\n",
    "                on_blur=State.set_prompt,\n",
    "                width=\"25em\",\n",
    "                border_color=\"#1c2024\",\n",
    "            ),\n",
    "            rx.button(\n",
    "                \"suggest continuation\", \n",
    "                on_click=State.get_suggestion,\n",
    "                width=\"25em\",\n",
    "                loading=State.processing, \n",
    "                background_color=\"#1c2024\"\n",
    "            ),\n",
    "            rx.cond(\n",
    "                State.complete,\n",
    "                rx.text(State.suggested_text, text_align=\"center\", font_weight=\"bold\", color=\"black\")\n",
    "            ),\n",
    "            align=\"center\",\n",
    "        ),\n",
    "        width=\"100%\",\n",
    "        height=\"100vh\",\n",
    "        background=\"linear-gradient(to right, #a8c0ff, #3f2b96)\"\n",
    "    )\n",
    "\n",
    "app = rx.App()\n",
    "app.add_page(index, title=\"Text suggestion online!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отчет\n",
    "\n",
    "Итак, мы сделали полноценную пользовательскую систему продолжения текста!\n",
    "\n",
    "Ее основа базируется на N-граммной модели: мы подсчитываем все N-граммы в нашем корпусе текстов, отмечая, как часто после каждой из них встречаются те или иные слова (для скорости пользуемся префиксным деревом). Далее, мы считаем вероятности (деля количество раз, когда N-грамма продолжилась определенным словом, на все количество вхождений данной N-граммы), сортируем наши продолжения N-грамм по ним, и жадным способом на каждой итерации (при предсказании каждого последующего слова) ищем самое вероятное продолжение. Продолжения слов мы дописываем, ища самое частотное слово с таким же началом в словаре.\n",
    "\n",
    "В качестве корпуса слов мы используем датасет электронных писем, состоящий из 500 000 сообщений (предварительно предобработанный, очищенный от метаданных, цифр, пунктуации, иных спец. символов).\n",
    "\n",
    "После мы оборачиваем нашу систему в пользовательский интерфейс при помощи фреймворка reflex: у нас получился сайт, где пользователь может ввести в строку последовательность слов и получить нажатием кнопки наиболее вероятное продолжение.\n",
    "\n",
    "По инструкции reflex, я отредактировала дефолтный State класс, который согласно функционалу нашего приложения подает на выход самый вероятный ответ подсказчика текста. Со стороны фронта через функцию index создала привлекательный дизайн, приятный глазу и понятный пользователю. \n",
    "\n",
    "В качестве улучшения базового варианта системы мной были предложены и реализованы: фильтрация редких н-грамм (отбрасывание тех, что встречаются меньше 2 раз), подсказка более одного варианта продолжения текста посредством выбора второго лучшего варианта на первой итерации предсказания, подходящая предобработка промпта (предобработка, аналогичная предобработке входных данных).\n",
    "\n",
    "С какими проблемами я столкнулась и какие перспективы их решения существуют?\n",
    "\n",
    "1. На локальном сервере в режиме реального времени невозможно обрабатывать большие количества данных. Это сильно снижает предсказательные способности нашей системы, потому что сервер просто падает при попытке предобработать входные данные. Я тестировала систему на маленьком кусочке датасета, чтобы она была работоспособна и относительно быстро отвечала. Это вопрос ограничения производительности оборудования\n",
    "\n",
    "2. Конечно, жадный метод выбора продолжений не слишком оптимален. Хотелось бы заменить его максимизацией вероятности/качества/отбором наиболее информативных n-грамм в будущем (entropy-based)\n",
    "   \n",
    "   \n",
    "4. Так же я не смогла реализовать вывод произвольного количества предсказаний во фронт. Конечно, это сложно и с точки зрения технической (самой поддержки фронта, лично для меня было подвигом выводить даже одно предсказание, не то что несколько :( ), и с точки зрения написания самого алгоритма. Следствие из жадного метода - я делала это итеративными предсказаниями вручную, а было бы здорово, если бы наша система умела в зависимости от того, сколько связанных со словом/предложением н-грамм есть, выдавать разное количество предсказаний (по трешхолду вероятности или по количеству вхождений n-граммы и ее продолжения), или даже в режиме реального времени мочь их изменять (количество и само содержание). Но я на данном этапе даже не представляю, как можно было бы это реализовать, поэтому считаю, что это тема для отдельного маленького проекта\n",
    "\n",
    "5. Конечно, в контексте продолжения слова, нашей голубой мечтой было бы, чтобы мы как-то реагировали даже на те слова, которые в нашем корпусе слов отсутствуют, потому что сейчас наша система вообще такие случаи не умеет обрабатывать и просто выдает пустой вывод. Это можно сделать либо расширением данных (хотя это вопроса полностью не решит, так как есть новый появляющийся сленг, и данные не будут успевать обновляться, есть опечатки), либо предсказанием n-грамм внутри слова (уже внутри слова смотреть какие сочетания букв самые популярные и пытаться достроить слово), либо fuzzy string matching - по какой-нибудь метрике (cosine, jaccard) искать на какое слово больше всего похоже введенное, мне кажется последнее было бы самым оптимальным.\n",
    "\n",
    "6. Оптимизация гиперпараметров. Я не подбирала n и количество возвращаемых слов, но было бы здорово измерить и понять, какие дают лучшее качество (во втором случае мы бы измеряли когда добавление новых слов начинает ухудшать качество и тогда бы переставали их добавлять, либо просто ориентировались бы на трешхолд). Но здесь, конечно, отдельной задачей стоит сам выбор функционала качества, так что задача не так проста, как кажется\n",
    "\n",
    "7. Другие аспекты оптимизации: более широкий функционал приложения, учет каких-то краевых случаев (а что, если у нас вообще нет продолжений, а что, если нет второго/третьего продолжения, а что, если пользователь введет слово на русском или что-то другое нетипичное и так далее), использование большего количества данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "notebookId": "53997d2d-afb8-4477-8874-b6d46299f06c",
  "notebookPath": "seminar.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
